{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 3 - Emotion Recognition\n",
        "## Convoluted Feelings\n",
        "\n",
        "\n",
        "### Data\n",
        "For this exercise, you will be working on the Twitter Emotion Recognition task. The goal of this task is to infer the\n",
        "affectual state of a person from their tweet. You will be using the Tweeteval dataset to train your model. You can\n",
        "access the related GitHub repositories from the links below.\n",
        "\n",
        "● Tweeteval Repository: https://github.com/cardiffnlp/tweeteval\n",
        "\n",
        "● Emotion Detection (our task): https://github.com/cardiffnlp/tweeteval/tree/main/datasets/emotion\n",
        "\n",
        "The ability to process and load custom datasets for your projects/research is an important skill. Most tasks you will\n",
        "complete as an NLP practitioner/researcher will require you to handle different data sources, formats, and files.\n",
        "Therefore, we want you to figure out how to load the emotion recognition dataset from its respective repository\n",
        "using all the necessary files (e.g., train_text.txt, train_labels.txt, mapping.txt) and train your model.\n",
        "\n",
        "### Task: Emotion Recognition with a CNN\n",
        "Implement an emotion recognition classifier in PyTorch or PyTorch Lightning. You can reuse the class structure\n",
        "from exercise 2, which is an adaption from Rao and McMahan. However, you are free to create your own, new\n",
        "class structure. Keep in mind that for emotion prediction, unlike in Exercise 1, we work on the word level instead of\n",
        "the character level. Thus, your Vocabulary class (if you have one) will not hold a vocabulary of characters.\n",
        "Remember to document your code with docstrings and/or comments and/or text cells.\n",
        "1. Pick two different emotion classes for your model to predict (e.g., anger and joy). Load/filter your\n",
        "dataset to include only the related class data. Create another dataset and change only one of the\n",
        "classes (e.g., anger and sadness) this time.\n",
        "2. Your goal is to find the optimal model architecture and training regime for your CNN classifier. Pick one\n",
        "of the datasets you created and start experimenting. Experiment with at least three different combinations\n",
        "(sets) of hyperparameters, with at least two different values each, e.g., optimizer, learning rate, dropout,\n",
        "number of filters, stride, kernel size, pooling, and batch size. Report the combinations and corresponding\n",
        "results (accuracy and F1-macro) on the development set in a table:\n",
        "3. Use your best-performing model settings to train another model on the second dataset. Report\n",
        "the model performance (accuracy and F1-macro) on the test set of both datasets.\n",
        "4. What could be the reason that the specific combination/values of hyperparameters resulted in the best\n",
        "model performance? Don’t worry about the exact reasoning, the goal is just to provide educated (or wellreasoned) guesses."
      ],
      "metadata": {
        "id": "6UjL01foVLGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1-Diq3ynW0W",
        "outputId": "8fe63a21-b09e-4e3a-f872-fcbc4bc5384b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import random\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import torch.utils.data as data, torchvision as tv\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "V5kphn2SnaIS"
      },
      "execution_count": 282,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.blank('en')"
      ],
      "metadata": {
        "id": "SHsIC7Pnnd5L"
      },
      "execution_count": 283,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read data\n",
        "Reading each lines in the data and it's corresponding labels below."
      ],
      "metadata": {
        "id": "ceh8DPWId2A-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_text(text_path):\n",
        "  with open(text_path, 'r') as file:\n",
        "        text_data = file.read().splitlines()\n",
        "  return text_data\n",
        "\n",
        "def read_labels(label_path):\n",
        "  with open(label_path, 'r') as file:\n",
        "        label_data = file.read().splitlines()\n",
        "  return label_data"
      ],
      "metadata": {
        "id": "OWtdKEIraNTs"
      },
      "execution_count": 284,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Train, Validation, Test data\n",
        "Loading train, validation, and test dataset and labels"
      ],
      "metadata": {
        "id": "hTE-VRgeeAa1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_txt_file = \"train_text.txt\"\n",
        "train_label_file = \"train_labels.txt\"\n",
        "train_data = read_text(train_txt_file)\n",
        "train_labels = read_labels(train_label_file)\n",
        "\n",
        "val_txt_file = \"val_text.txt\"\n",
        "val_label_file = \"val_labels.txt\"\n",
        "val_data = read_text(val_txt_file)\n",
        "val_labels = read_labels(val_label_file)\n",
        "\n",
        "test_txt_file = \"test_text.txt\"\n",
        "test_label_file = \"test_labels.txt\"\n",
        "test_data = read_text(test_txt_file)\n",
        "test_labels = read_labels(test_label_file)"
      ],
      "metadata": {
        "id": "M-4PqbHgaXwL"
      },
      "execution_count": 285,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example data\n",
        "Example of how data and labels look like. Mappings are as follows:\n",
        "\n",
        "0 ---> Anger\n",
        "\n",
        "1 ---> Joy\n",
        "\n",
        "2 ---> Optimism\n",
        "\n",
        "3 ---> Sadness"
      ],
      "metadata": {
        "id": "zQdiji_geOMm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0], train_labels[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45TAlr1Wbf2X",
        "outputId": "e94957c5-53ec-4564-be91-66df62e9bcec"
      },
      "execution_count": 286,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\"“Worry is a down payment on a problem you may never have'. \\xa0Joyce Meyer.  #motivation #leadership #worry \",\n",
              " '2')"
            ]
          },
          "metadata": {},
          "execution_count": 286
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_data[0], val_labels[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iw-HoXi_cmTF",
        "outputId": "2b492566-3b02-46f7-aa9f-0a854bdd2fa9"
      },
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('@user @user Oh, hidden revenge and anger...I rememberthe time,she rebutted you. ',\n",
              " '0')"
            ]
          },
          "metadata": {},
          "execution_count": 287
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data[0], test_labels[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiHmlM0LeZLv",
        "outputId": "1fcfc38d-7aea-4658-8ed4-8a36f4aa8687"
      },
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('#Deppression is real. Partners w/ #depressed people truly dont understand the depth in which they affect us. Add in #anxiety &amp;makes it worse ',\n",
              " '3')"
            ]
          },
          "metadata": {},
          "execution_count": 288
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNHRoV9hei38",
        "outputId": "a069aaee-4070-43a8-c2aa-41da81e5e703"
      },
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"“Worry is a down payment on a problem you may never have'. \\xa0Joyce Meyer.  #motivation #leadership #worry \",\n",
              " \"My roommate: it's okay that we can't spell because we have autocorrect. #terrible #firstworldprobs \",\n",
              " \"No but that's so cute. Atsu was probably shy about photos before but cherry helped her out uwu \",\n",
              " \"Rooneys fucking untouchable isn't he? Been fucking dreadful again, depay has looked decent(ish)tonight \",\n",
              " \"it's pretty depressing when u hit pan on ur favourite highlighter \"]"
            ]
          },
          "metadata": {},
          "execution_count": 289
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4oE_P_sgGR0",
        "outputId": "77ceb634-8291-41f5-813a-3676cb9a54ed"
      },
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['2', '0', '1', '0', '3']"
            ]
          },
          "metadata": {},
          "execution_count": 290
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Proprocess and clean text data\n",
        "1. we decoded ascii values\n",
        "2. we removed all the tags for eg: @user, @john, etc\n",
        "3. we remove all the words which were # in it\n",
        "4. we removed all the puncuations\n",
        "5. we removed all the stopwords\n",
        "6. we applied Lemmatization"
      ],
      "metadata": {
        "id": "Ty00lSv6vY9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Initialize WordNet Lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Function to preprocess and lemmatize text\n",
        "def preprocess_text(text, clean_hastag_words = False, remove_username = False):\n",
        "    # Remove unwanted characters\n",
        "    text = text.encode('ascii', 'ignore').decode('ascii')\n",
        "\n",
        "\n",
        "    if remove_username:\n",
        "      text = re.sub(r'@\\w+', '', text)\n",
        "    if clean_hastag_words:\n",
        "      text = re.sub(r'#\\w+', '', text)\n",
        "\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "\n",
        "    # Tokenize the text\n",
        "    tokens = word_tokenize(text.lower())\n",
        "\n",
        "    # Remove stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Lemmatization\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "    return ' '.join(lemmatized_tokens)\n",
        "\n",
        "# Apply preprocessing to each text in the data\n",
        "train_data = [preprocess_text(text, clean_hastag_words=True, remove_username=True) for text in train_data]\n",
        "val_data = [preprocess_text(text, clean_hastag_words=True, remove_username=True) for text in val_data]\n",
        "test_data = [preprocess_text(text, clean_hastag_words=True, remove_username=True) for text in test_data]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBka5tw4dsTe",
        "outputId": "10f389c3-7953-45fe-a5f2-0c7ae79cc46b"
      },
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 1: Emotional Recognition Model: Anger or Joy\n",
        "\n",
        "In this section, we will choose data from anger (0) and joy (1) classes and train a Emotion Recognition model using only these two classes."
      ],
      "metadata": {
        "id": "D2AK_KlMg0C9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_d_aj = [data for data, label in zip(train_data, train_labels) if label in ('0', '1')]\n",
        "train_l_aj = [label for label in train_labels if label in ('0', '1')]\n",
        "\n",
        "val_d_aj = [data for data, label in zip(val_data, val_labels) if label in ('0', '1')]\n",
        "val_l_aj = [label for label in val_labels if label in ('0', '1')]\n",
        "\n",
        "test_d_aj = [data for data, label in zip(test_data, test_labels) if label in ('0', '1')]\n",
        "test_l_aj = [label for label in test_labels if label in ('0', '1')]"
      ],
      "metadata": {
        "id": "rom7gAFTgNlJ"
      },
      "execution_count": 292,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_l_aj.count(\"0\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yN4E23DxolEz",
        "outputId": "b1f0e9d4-c053-43cf-9cad-b06db817297d"
      },
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1400"
            ]
          },
          "metadata": {},
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_l_aj.count(\"1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfnSsBEfo7WT",
        "outputId": "3d9249f0-6fe3-4dce-bd99-4ccde5ad2e05"
      },
      "execution_count": 294,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "708"
            ]
          },
          "metadata": {},
          "execution_count": 294
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data balancing\n",
        "\n",
        "As observed above, our classes are not balanced, therefore we will upsample the minority class using the function below."
      ],
      "metadata": {
        "id": "0H2C4navm1xZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def balance_dataset(dataset, labels):\n",
        "  import random\n",
        "  # Concatenate the training data and labels\n",
        "  train_data_labels = list(zip(dataset, labels))\n",
        "\n",
        "  # Extract minority and majority classes\n",
        "  minority_class = [(data, label) for data, label in train_data_labels if label == '1']\n",
        "  majority_class = [(data, label) for data, label in train_data_labels if label == '0']\n",
        "\n",
        "  # Calculate the required oversampling ratio\n",
        "  oversampling_ratio = len(majority_class) // len(minority_class)\n",
        "\n",
        "  # Randomly replicate instances from the minority class\n",
        "  minority_upsampled = random.choices(minority_class, k=len(majority_class) * oversampling_ratio)\n",
        "\n",
        "  # Combine minority and majority classes\n",
        "  upsampled_data_labels = majority_class + minority_upsampled\n",
        "\n",
        "  # Shuffle the upsampled dataset to ensure randomness\n",
        "  random.shuffle(upsampled_data_labels)\n",
        "\n",
        "  # Extract upsampled data and labels\n",
        "  upsampled_data, upsampled_labels = zip(*upsampled_data_labels)\n",
        "\n",
        "  return upsampled_data, upsampled_labels"
      ],
      "metadata": {
        "id": "9n5CdhDOnasJ"
      },
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Balance the classes"
      ],
      "metadata": {
        "id": "djCInD66xzIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_d_aj, train_l_aj =  balance_dataset(train_d_aj, train_l_aj)\n",
        "val_d_aj, val_l_aj =  balance_dataset(val_d_aj, val_l_aj)\n",
        "test_d_aj, test_l_aj =  balance_dataset(test_d_aj, test_l_aj)"
      ],
      "metadata": {
        "id": "hF6g7P_Lnx8M"
      },
      "execution_count": 296,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_l_aj.count(\"0\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHpTWATpp8tH",
        "outputId": "c51ce5e0-6b29-42e2-8861-4a2d3e3a873a"
      },
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1400"
            ]
          },
          "metadata": {},
          "execution_count": 297
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_l_aj.count(\"1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9altOIv_qDCD",
        "outputId": "1afda6fd-326a-4eff-cccb-3c00c1e8dd9a"
      },
      "execution_count": 298,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1400"
            ]
          },
          "metadata": {},
          "execution_count": 298
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Examples of filtered data:"
      ],
      "metadata": {
        "id": "StHawLHclMxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_d_aj[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpHQBC7mlA3W",
        "outputId": "11911ac5-6dc0-4ab6-ea8a-9262dbaf193b"
      },
      "execution_count": 299,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('sparkling look like gay vampire',\n",
              " 'people angry toward veggie burger n wtf',\n",
              " 'thenicebot wsjnordics make world joyful place',\n",
              " 'ha right im san jose ca offended right dave go walk something next time',\n",
              " 'snap hialeshia',\n",
              " 'got ta wonder caller max listens show first place incense',\n",
              " 'might get donal g sure wont cork he fiery dopey frank amp cult',\n",
              " 'intense emotional response',\n",
              " 'opinion worst delhi govt',\n",
              " 'yall remember mlb tried futuristic jersey')"
            ]
          },
          "metadata": {},
          "execution_count": 299
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_l_aj[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfkZwolUlDqd",
        "outputId": "1906f29e-b8b4-429e-9f7f-263b51980f0e"
      },
      "execution_count": 300,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('1', '0', '1', '0', '1', '0', '0', '0', '0', '1')"
            ]
          },
          "metadata": {},
          "execution_count": 300
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_l_aj[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q92KRQIgvjQ",
        "outputId": "900a5edf-2741-4f92-b244-bcf3c990d775"
      },
      "execution_count": 301,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('0', '1', '0', '0', '1', '1', '1', '1', '1', '0')"
            ]
          },
          "metadata": {},
          "execution_count": 301
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tokenize, encode, converting to tensor functions. Reference of tokenize, encode functions: tutorial notebook"
      ],
      "metadata": {
        "id": "7cFXWl2Jp_7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(texts):\n",
        "  max_len = 0\n",
        "  tokenized_texts = []\n",
        "  word2idx = {}\n",
        "\n",
        "  # Add <pad> and <unk> tokens to the vocabulary\n",
        "  word2idx['<pad>'] = 0\n",
        "  word2idx['<unk>'] = 1\n",
        "\n",
        "  # Building our vocab from the corpus starting from index 2\n",
        "  idx = 2\n",
        "  for sent in texts:\n",
        "    tokenized_sent = nlp(sent)\n",
        "    # Add `tokenized_sent` to `tokenized_texts`\n",
        "    tokenized_texts.append(tokenized_sent)\n",
        "    # Add new token to `word2idx`\n",
        "    for token in tokenized_sent:\n",
        "      # string any token objects are different things, be careful.\n",
        "      if token.text not in word2idx:\n",
        "        word2idx[token.text] = idx\n",
        "        idx += 1\n",
        "\n",
        "        # Update `max_len`\n",
        "    max_len = max(max_len, len(tokenized_sent))\n",
        "\n",
        "  return tokenized_texts, word2idx, max_len\n",
        "\n",
        "\n",
        "def encode(tokenized_texts, word2idx, max_len):\n",
        "    input_ids = []\n",
        "    for tokenized_sent in tokenized_texts:\n",
        "        # Pad sentences to e\n",
        "        tokenized_padded_sent = list(tokenized_sent) + ['<pad>'] * (max_len - len(tokenized_sent))\n",
        "\n",
        "        # Encode tokens to input_ids\n",
        "        input_id = [word2idx.get(str(token)) for token in tokenized_padded_sent]\n",
        "        input_ids.append(input_id)\n",
        "\n",
        "    return np.array(input_ids), word2idx\n",
        "\n",
        "\n",
        "def get_tokenized_encoded_ids(text):\n",
        "  # get tokenized and encoded data input ids\n",
        "  tokenized_texts, word2idx, max_len = tokenize(text)\n",
        "  input_ids, word2idx = encode(tokenized_texts, word2idx, max_len)\n",
        "  # converting input ids to torch.Tensor\n",
        "  input_ids = torch.from_numpy(input_ids)\n",
        "  return input_ids, word2idx\n",
        "\n",
        "def get_tensor_labels(labels):\n",
        "  # converting labels to torch.Tensor\n",
        "  label_int = [int(item) for item in labels]\n",
        "  label_tensors = torch.tensor(label_int)\n",
        "  return label_tensors"
      ],
      "metadata": {
        "id": "x51AP25tlTTg"
      },
      "execution_count": 302,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizing, encoding, converting to tensors\n",
        "train_id_aj, word2idx = get_tokenized_encoded_ids(train_d_aj)\n",
        "val_id_aj, _ = get_tokenized_encoded_ids(val_d_aj)\n",
        "test_id_aj, _ = get_tokenized_encoded_ids(test_d_aj)\n",
        "\n",
        "# converting labels to tensors\n",
        "train_l_aj = get_tensor_labels(train_l_aj)\n",
        "val_l_aj = get_tensor_labels(val_l_aj)\n",
        "test_l_aj = get_tensor_labels(test_l_aj)"
      ],
      "metadata": {
        "id": "ijSLCF0vaHBG"
      },
      "execution_count": 303,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example of dataset after tokenization, encoding, and converting to tensors"
      ],
      "metadata": {
        "id": "hIojtR56p2Pa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_id_aj[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yX5G6DWvn8vA",
        "outputId": "a521fa8d-e7fc-40ca-a4ee-0bd063c256c9"
      },
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2,  3,  4,  5,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 7,  8,  9, 10, 11, 12, 13,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [14, 15, 16, 17, 18, 19,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [20, 21, 22, 23, 24, 25, 26, 27, 21, 28, 29, 30, 31, 32, 33,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [34, 35,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0]])"
            ]
          },
          "metadata": {},
          "execution_count": 304
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_l_aj[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fkb0GVzLn-Gq",
        "outputId": "b5f82e7e-ced2-49bd-e00d-776a7b00f405"
      },
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 0, 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 305
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create dataset and dataloader objects from tensors of data. Dataloader object will be used in training."
      ],
      "metadata": {
        "id": "3RgfoyDuqSFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_seed = 42\n",
        "train_dataset = TensorDataset(train_id_aj, train_l_aj)\n",
        "train_sampler = RandomSampler(train_dataset, generator=torch.Generator().manual_seed(random_seed))\n",
        "\n",
        "val_dataset = TensorDataset(val_id_aj, val_l_aj)\n",
        "test_dataset = TensorDataset(test_id_aj, test_l_aj)\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "h_UISpbBpMF_"
      },
      "execution_count": 306,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchtext.vocab as vocab\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, embed_dim, filter_sizes, num_filters, num_classes, dropout, pretrained_embeddings, vocab_size=len(word2idx)):\n",
        "        super(CNN, self).__init__()\n",
        "        if pretrained_embeddings is not None:\n",
        "            print(\"using pretrained embedding\")\n",
        "            glove = vocab.GloVe(name='6B', dim=embed_dim)\n",
        "            self.embedding = nn.Embedding.from_pretrained(glove.vectors, freeze=True)\n",
        "        else:\n",
        "            print(\"training embedding\")\n",
        "            self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embed_dim, padding_idx=0)\n",
        "        self.conv1d_list = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Conv1d(in_channels=embed_dim, out_channels=num_filters[i], kernel_size=filter_sizes[i]),\n",
        "                nn.BatchNorm1d(num_filters[i]),\n",
        "                nn.LeakyReLU(negative_slope=0.01),\n",
        "                nn.MaxPool1d(kernel_size=filter_sizes[i])\n",
        "            )\n",
        "            for i in range(len(filter_sizes))\n",
        "        ])\n",
        "        self.fc = nn.Linear(np.sum(num_filters), num_classes)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        x_embed = self.embedding(input_ids).float()\n",
        "        x_reshaped = x_embed.permute(0, 2, 1)\n",
        "        x_conv_list = [F.relu(conv1d(x_reshaped)) for conv1d in self.conv1d_list]\n",
        "        x_pool_list = [F.max_pool1d(x_conv, kernel_size=x_conv.shape[2])\n",
        "            for x_conv in x_conv_list]\n",
        "\n",
        "        x_fc = torch.cat([x_pool.squeeze(dim=2) for x_pool in x_pool_list],\n",
        "                         dim=1)\n",
        "        logits = self.fc(self.dropout(x_fc))\n",
        "        return logits"
      ],
      "metadata": {
        "id": "-V8LzL8kb8kZ"
      },
      "execution_count": 307,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Train:\n",
        "  def __init__(\n",
        "      self,\n",
        "      embed_dim=100,\n",
        "      filter_sizes=[3, 4, 5],\n",
        "      num_filters=[150, 150, 150],\n",
        "      dropout=0.2,\n",
        "      num_classes=2,\n",
        "      lr=0.01,\n",
        "      rho=0.95,\n",
        "      epoch=5,\n",
        "      pretrained_embeddings=None,\n",
        "      weight_decay = 1e-5\n",
        "    ):\n",
        "    self._embed_dim = embed_dim\n",
        "    self._filter_sizes = filter_sizes\n",
        "    self._num_filters = num_filters\n",
        "    self._dropout = dropout\n",
        "    self._num_classes = num_classes\n",
        "    self._lr = lr\n",
        "    self._rho = rho\n",
        "    self._epoch = epoch\n",
        "    self._pretrained_embeddings = pretrained_embeddings\n",
        "    self._weight_decay = weight_decay\n",
        "\n",
        "  def train_model(self, device, train_dataloader, validation_dataloader):\n",
        "    # Instantiate CNN model\n",
        "    model = CNN(embed_dim=self._embed_dim,\n",
        "                filter_sizes=self._filter_sizes,\n",
        "                num_filters=self._num_filters,\n",
        "                num_classes=self._num_classes,\n",
        "                dropout=self._dropout,\n",
        "                pretrained_embeddings=self._pretrained_embeddings)\n",
        "\n",
        "    # Send model to `device` (GPU/CPU)\n",
        "    model.to(device)\n",
        "\n",
        "    # Instantiate SDG Optimizer\n",
        "    optimizer = optim.SGD(model.parameters(), lr=self._lr, weight_decay=self._weight_decay)\n",
        "\n",
        "    # cross entropy loss function\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Start training loop\n",
        "    print(\"Start training...\\n\")\n",
        "    best_validation_loss = float('inf')\n",
        "    best_validation_macro = 0\n",
        "    best_model = None\n",
        "\n",
        "    for epoch_i in range(self._epoch):\n",
        "        total_train_loss = 0\n",
        "        total_validation_loss = 0\n",
        "        y_true_t = []\n",
        "        y_pred_t = []\n",
        "\n",
        "        y_true_v = []\n",
        "        y_pred_v = []\n",
        "\n",
        "        # Put the model into the training mode\n",
        "        model.train()\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            # Load batch to GPU\n",
        "            b_input_ids, b_labels = tuple(t.to(device) for t in batch)\n",
        "            model.zero_grad()\n",
        "            logits = model(b_input_ids)\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            total_train_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            y_true_t.extend(b_labels.cpu().numpy())\n",
        "            y_pred_t.extend(logits.argmax(1).cpu().numpy())\n",
        "\n",
        "        # Calculate the average training loss\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "        # Calculate accuracy and F1-macro for the training data\n",
        "        train_accuracy = accuracy_score(y_true_t, y_pred_t)\n",
        "        train_f1_macro = f1_score(y_true_t, y_pred_t, average='macro')\n",
        "\n",
        "        # Put the model into evaluation mode\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for step, batch in enumerate(validation_dataloader):\n",
        "                b_input_ids, b_labels = tuple(t.to(device) for t in batch)\n",
        "                logits = model(b_input_ids)\n",
        "                loss = loss_fn(logits, b_labels)\n",
        "                total_validation_loss += loss.item()\n",
        "                y_true_v.extend(b_labels.cpu().numpy())\n",
        "                y_pred_v.extend(logits.argmax(1).cpu().numpy())\n",
        "\n",
        "        # Calculate the average validation loss\n",
        "        avg_validation_loss = total_validation_loss / len(validation_dataloader)\n",
        "\n",
        "        # Calculate accuracy and F1-macro for the validation data\n",
        "        val_accuracy = accuracy_score(y_true_v, y_pred_v)\n",
        "        val_f1_macro = f1_score(y_true_v, y_pred_v, average='macro')\n",
        "\n",
        "        # Save the best model based on validation loss\n",
        "        #if avg_validation_loss < best_validation_loss:\n",
        "        #    best_validation_loss = avg_validation_loss\n",
        "        #    best_model = model.state_dict()\n",
        "\n",
        "        if val_accuracy > best_validation_macro:\n",
        "            best_validation_macro = val_accuracy\n",
        "            best_model = model.state_dict()\n",
        "\n",
        "\n",
        "        print(f\"Epoch {epoch_i + 1:2d} | Train Loss: {avg_train_loss:.6f} | Train Acc: {train_accuracy:.4f} | Train F1-Macro: {train_f1_macro:.4f}\")\n",
        "        print(f\"Epoch {epoch_i + 1:2d} | Validation Loss: {avg_validation_loss:.6f} | Validation Acc: {val_accuracy:.4f} | Validation F1-Macro: {val_f1_macro:.4f}\")\n",
        "        print(\".........................................................................................\")\n",
        "\n",
        "    # Load the best model for further evaluation or testing\n",
        "    model.load_state_dict(best_model)\n",
        "    return model"
      ],
      "metadata": {
        "id": "Qvo4y3fE7HBO"
      },
      "execution_count": 308,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, device, test_dataloader):\n",
        "  model.eval()\n",
        "  y_true = []\n",
        "  y_pred = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for step, batch in enumerate(test_dataloader):\n",
        "          b_input_ids, b_labels = tuple(t.to(device) for t in batch)\n",
        "          logits = model(b_input_ids)\n",
        "          y_true.extend(b_labels.cpu().numpy())\n",
        "          y_pred.extend(logits.argmax(1).cpu().numpy())\n",
        "\n",
        "  test_accuracy = accuracy_score(y_true, y_pred)\n",
        "  test_f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "  print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "  print(f\"Test F1-Macro: {test_f1_macro:.4f}\")"
      ],
      "metadata": {
        "id": "Dx2f1crTS3Bh"
      },
      "execution_count": 309,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "# use the GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iEBuzKm8sal",
        "outputId": "b95c0d19-016b-4198-9b50-cad1d45c6d89"
      },
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiments on different Hyperparameter"
      ],
      "metadata": {
        "id": "euU_iVmezPua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_obj = Train(embed_dim=300, pretrained_embeddings=True, epoch=50, lr=0.0001, dropout=0.2, weight_decay=0.00001, filter_sizes=[3, 3, 4, 5], num_filters=[100, 100, 100, 100])\n",
        "model = train_obj.train_model(device, train_dataloader, val_dataloader)\n",
        "test_model(model, device, test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlU9kPgluTNo",
        "outputId": "08c624fd-dc1a-44fc-ef63-413b81acbdc7"
      },
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using pretrained embedding\n",
            "Start training...\n",
            "\n",
            "Epoch  1 | Train Loss: 0.874927 | Train Acc: 0.4882 | Train F1-Macro: 0.4882\n",
            "Epoch  1 | Validation Loss: 0.723704 | Validation Acc: 0.4750 | Validation F1-Macro: 0.4675\n",
            ".........................................................................................\n",
            "Epoch  2 | Train Loss: 0.849021 | Train Acc: 0.4989 | Train F1-Macro: 0.4970\n",
            "Epoch  2 | Validation Loss: 0.742905 | Validation Acc: 0.4688 | Validation F1-Macro: 0.4627\n",
            ".........................................................................................\n",
            "Epoch  3 | Train Loss: 0.847134 | Train Acc: 0.5050 | Train F1-Macro: 0.5042\n",
            "Epoch  3 | Validation Loss: 0.740420 | Validation Acc: 0.4781 | Validation F1-Macro: 0.4711\n",
            ".........................................................................................\n",
            "Epoch  4 | Train Loss: 0.844374 | Train Acc: 0.5104 | Train F1-Macro: 0.5090\n",
            "Epoch  4 | Validation Loss: 0.738017 | Validation Acc: 0.4719 | Validation F1-Macro: 0.4655\n",
            ".........................................................................................\n",
            "Epoch  5 | Train Loss: 0.827155 | Train Acc: 0.5143 | Train F1-Macro: 0.5132\n",
            "Epoch  5 | Validation Loss: 0.735435 | Validation Acc: 0.4844 | Validation F1-Macro: 0.4821\n",
            ".........................................................................................\n",
            "Epoch  6 | Train Loss: 0.828167 | Train Acc: 0.5089 | Train F1-Macro: 0.5085\n",
            "Epoch  6 | Validation Loss: 0.732805 | Validation Acc: 0.4906 | Validation F1-Macro: 0.4884\n",
            ".........................................................................................\n",
            "Epoch  7 | Train Loss: 0.817028 | Train Acc: 0.5300 | Train F1-Macro: 0.5291\n",
            "Epoch  7 | Validation Loss: 0.730618 | Validation Acc: 0.4813 | Validation F1-Macro: 0.4792\n",
            ".........................................................................................\n",
            "Epoch  8 | Train Loss: 0.802511 | Train Acc: 0.5368 | Train F1-Macro: 0.5361\n",
            "Epoch  8 | Validation Loss: 0.728596 | Validation Acc: 0.5125 | Validation F1-Macro: 0.5125\n",
            ".........................................................................................\n",
            "Epoch  9 | Train Loss: 0.796176 | Train Acc: 0.5311 | Train F1-Macro: 0.5309\n",
            "Epoch  9 | Validation Loss: 0.726444 | Validation Acc: 0.5062 | Validation F1-Macro: 0.5059\n",
            ".........................................................................................\n",
            "Epoch 10 | Train Loss: 0.798314 | Train Acc: 0.5307 | Train F1-Macro: 0.5304\n",
            "Epoch 10 | Validation Loss: 0.725300 | Validation Acc: 0.5250 | Validation F1-Macro: 0.5250\n",
            ".........................................................................................\n",
            "Epoch 11 | Train Loss: 0.784121 | Train Acc: 0.5336 | Train F1-Macro: 0.5332\n",
            "Epoch 11 | Validation Loss: 0.723548 | Validation Acc: 0.5312 | Validation F1-Macro: 0.5312\n",
            ".........................................................................................\n",
            "Epoch 12 | Train Loss: 0.764117 | Train Acc: 0.5479 | Train F1-Macro: 0.5476\n",
            "Epoch 12 | Validation Loss: 0.720591 | Validation Acc: 0.5281 | Validation F1-Macro: 0.5281\n",
            ".........................................................................................\n",
            "Epoch 13 | Train Loss: 0.770903 | Train Acc: 0.5675 | Train F1-Macro: 0.5672\n",
            "Epoch 13 | Validation Loss: 0.720328 | Validation Acc: 0.5281 | Validation F1-Macro: 0.5281\n",
            ".........................................................................................\n",
            "Epoch 14 | Train Loss: 0.755918 | Train Acc: 0.5511 | Train F1-Macro: 0.5510\n",
            "Epoch 14 | Validation Loss: 0.718101 | Validation Acc: 0.5156 | Validation F1-Macro: 0.5154\n",
            ".........................................................................................\n",
            "Epoch 15 | Train Loss: 0.762085 | Train Acc: 0.5525 | Train F1-Macro: 0.5520\n",
            "Epoch 15 | Validation Loss: 0.717875 | Validation Acc: 0.5750 | Validation F1-Macro: 0.5730\n",
            ".........................................................................................\n",
            "Epoch 16 | Train Loss: 0.747867 | Train Acc: 0.5625 | Train F1-Macro: 0.5622\n",
            "Epoch 16 | Validation Loss: 0.716682 | Validation Acc: 0.5719 | Validation F1-Macro: 0.5697\n",
            ".........................................................................................\n",
            "Epoch 17 | Train Loss: 0.754235 | Train Acc: 0.5639 | Train F1-Macro: 0.5635\n",
            "Epoch 17 | Validation Loss: 0.716602 | Validation Acc: 0.5687 | Validation F1-Macro: 0.5663\n",
            ".........................................................................................\n",
            "Epoch 18 | Train Loss: 0.736986 | Train Acc: 0.5604 | Train F1-Macro: 0.5601\n",
            "Epoch 18 | Validation Loss: 0.714189 | Validation Acc: 0.5625 | Validation F1-Macro: 0.5617\n",
            ".........................................................................................\n",
            "Epoch 19 | Train Loss: 0.735256 | Train Acc: 0.5743 | Train F1-Macro: 0.5742\n",
            "Epoch 19 | Validation Loss: 0.713010 | Validation Acc: 0.5656 | Validation F1-Macro: 0.5649\n",
            ".........................................................................................\n",
            "Epoch 20 | Train Loss: 0.730831 | Train Acc: 0.5807 | Train F1-Macro: 0.5804\n",
            "Epoch 20 | Validation Loss: 0.714532 | Validation Acc: 0.5594 | Validation F1-Macro: 0.5557\n",
            ".........................................................................................\n",
            "Epoch 21 | Train Loss: 0.733708 | Train Acc: 0.5779 | Train F1-Macro: 0.5776\n",
            "Epoch 21 | Validation Loss: 0.712286 | Validation Acc: 0.5594 | Validation F1-Macro: 0.5575\n",
            ".........................................................................................\n",
            "Epoch 22 | Train Loss: 0.726607 | Train Acc: 0.5725 | Train F1-Macro: 0.5723\n",
            "Epoch 22 | Validation Loss: 0.712984 | Validation Acc: 0.5687 | Validation F1-Macro: 0.5649\n",
            ".........................................................................................\n",
            "Epoch 23 | Train Loss: 0.733715 | Train Acc: 0.5807 | Train F1-Macro: 0.5807\n",
            "Epoch 23 | Validation Loss: 0.713191 | Validation Acc: 0.5687 | Validation F1-Macro: 0.5638\n",
            ".........................................................................................\n",
            "Epoch 24 | Train Loss: 0.709675 | Train Acc: 0.5843 | Train F1-Macro: 0.5843\n",
            "Epoch 24 | Validation Loss: 0.708666 | Validation Acc: 0.5687 | Validation F1-Macro: 0.5681\n",
            ".........................................................................................\n",
            "Epoch 25 | Train Loss: 0.706168 | Train Acc: 0.5957 | Train F1-Macro: 0.5957\n",
            "Epoch 25 | Validation Loss: 0.708502 | Validation Acc: 0.5625 | Validation F1-Macro: 0.5611\n",
            ".........................................................................................\n",
            "Epoch 26 | Train Loss: 0.708217 | Train Acc: 0.5889 | Train F1-Macro: 0.5887\n",
            "Epoch 26 | Validation Loss: 0.708754 | Validation Acc: 0.5813 | Validation F1-Macro: 0.5780\n",
            ".........................................................................................\n",
            "Epoch 27 | Train Loss: 0.711226 | Train Acc: 0.5800 | Train F1-Macro: 0.5800\n",
            "Epoch 27 | Validation Loss: 0.711085 | Validation Acc: 0.5719 | Validation F1-Macro: 0.5647\n",
            ".........................................................................................\n",
            "Epoch 28 | Train Loss: 0.679717 | Train Acc: 0.6021 | Train F1-Macro: 0.6021\n",
            "Epoch 28 | Validation Loss: 0.708576 | Validation Acc: 0.5875 | Validation F1-Macro: 0.5822\n",
            ".........................................................................................\n",
            "Epoch 29 | Train Loss: 0.685593 | Train Acc: 0.5989 | Train F1-Macro: 0.5989\n",
            "Epoch 29 | Validation Loss: 0.707297 | Validation Acc: 0.5813 | Validation F1-Macro: 0.5770\n",
            ".........................................................................................\n",
            "Epoch 30 | Train Loss: 0.685073 | Train Acc: 0.6061 | Train F1-Macro: 0.6061\n",
            "Epoch 30 | Validation Loss: 0.703972 | Validation Acc: 0.5813 | Validation F1-Macro: 0.5780\n",
            ".........................................................................................\n",
            "Epoch 31 | Train Loss: 0.671961 | Train Acc: 0.6189 | Train F1-Macro: 0.6189\n",
            "Epoch 31 | Validation Loss: 0.704863 | Validation Acc: 0.5875 | Validation F1-Macro: 0.5838\n",
            ".........................................................................................\n",
            "Epoch 32 | Train Loss: 0.671279 | Train Acc: 0.6064 | Train F1-Macro: 0.6064\n",
            "Epoch 32 | Validation Loss: 0.705551 | Validation Acc: 0.5781 | Validation F1-Macro: 0.5736\n",
            ".........................................................................................\n",
            "Epoch 33 | Train Loss: 0.681150 | Train Acc: 0.6100 | Train F1-Macro: 0.6100\n",
            "Epoch 33 | Validation Loss: 0.701277 | Validation Acc: 0.5906 | Validation F1-Macro: 0.5877\n",
            ".........................................................................................\n",
            "Epoch 34 | Train Loss: 0.667801 | Train Acc: 0.6239 | Train F1-Macro: 0.6238\n",
            "Epoch 34 | Validation Loss: 0.704512 | Validation Acc: 0.5781 | Validation F1-Macro: 0.5724\n",
            ".........................................................................................\n",
            "Epoch 35 | Train Loss: 0.669858 | Train Acc: 0.6164 | Train F1-Macro: 0.6164\n",
            "Epoch 35 | Validation Loss: 0.703207 | Validation Acc: 0.5844 | Validation F1-Macro: 0.5793\n",
            ".........................................................................................\n",
            "Epoch 36 | Train Loss: 0.678176 | Train Acc: 0.6175 | Train F1-Macro: 0.6174\n",
            "Epoch 36 | Validation Loss: 0.704822 | Validation Acc: 0.5781 | Validation F1-Macro: 0.5704\n",
            ".........................................................................................\n",
            "Epoch 37 | Train Loss: 0.649881 | Train Acc: 0.6404 | Train F1-Macro: 0.6404\n",
            "Epoch 37 | Validation Loss: 0.702825 | Validation Acc: 0.5781 | Validation F1-Macro: 0.5724\n",
            ".........................................................................................\n",
            "Epoch 38 | Train Loss: 0.655168 | Train Acc: 0.6343 | Train F1-Macro: 0.6343\n",
            "Epoch 38 | Validation Loss: 0.700181 | Validation Acc: 0.5875 | Validation F1-Macro: 0.5828\n",
            ".........................................................................................\n",
            "Epoch 39 | Train Loss: 0.647485 | Train Acc: 0.6271 | Train F1-Macro: 0.6271\n",
            "Epoch 39 | Validation Loss: 0.705573 | Validation Acc: 0.5625 | Validation F1-Macro: 0.5524\n",
            ".........................................................................................\n",
            "Epoch 40 | Train Loss: 0.647638 | Train Acc: 0.6432 | Train F1-Macro: 0.6432\n",
            "Epoch 40 | Validation Loss: 0.701186 | Validation Acc: 0.5813 | Validation F1-Macro: 0.5746\n",
            ".........................................................................................\n",
            "Epoch 41 | Train Loss: 0.643727 | Train Acc: 0.6389 | Train F1-Macro: 0.6389\n",
            "Epoch 41 | Validation Loss: 0.701142 | Validation Acc: 0.5813 | Validation F1-Macro: 0.5746\n",
            ".........................................................................................\n",
            "Epoch 42 | Train Loss: 0.648107 | Train Acc: 0.6354 | Train F1-Macro: 0.6353\n",
            "Epoch 42 | Validation Loss: 0.698853 | Validation Acc: 0.5906 | Validation F1-Macro: 0.5851\n",
            ".........................................................................................\n",
            "Epoch 43 | Train Loss: 0.646719 | Train Acc: 0.6429 | Train F1-Macro: 0.6428\n",
            "Epoch 43 | Validation Loss: 0.705568 | Validation Acc: 0.5625 | Validation F1-Macro: 0.5497\n",
            ".........................................................................................\n",
            "Epoch 44 | Train Loss: 0.643970 | Train Acc: 0.6364 | Train F1-Macro: 0.6364\n",
            "Epoch 44 | Validation Loss: 0.698328 | Validation Acc: 0.5844 | Validation F1-Macro: 0.5781\n",
            ".........................................................................................\n",
            "Epoch 45 | Train Loss: 0.630954 | Train Acc: 0.6561 | Train F1-Macro: 0.6561\n",
            "Epoch 45 | Validation Loss: 0.699529 | Validation Acc: 0.5813 | Validation F1-Macro: 0.5746\n",
            ".........................................................................................\n",
            "Epoch 46 | Train Loss: 0.633091 | Train Acc: 0.6361 | Train F1-Macro: 0.6361\n",
            "Epoch 46 | Validation Loss: 0.699260 | Validation Acc: 0.5781 | Validation F1-Macro: 0.5704\n",
            ".........................................................................................\n",
            "Epoch 47 | Train Loss: 0.621297 | Train Acc: 0.6568 | Train F1-Macro: 0.6568\n",
            "Epoch 47 | Validation Loss: 0.701432 | Validation Acc: 0.5781 | Validation F1-Macro: 0.5680\n",
            ".........................................................................................\n",
            "Epoch 48 | Train Loss: 0.628501 | Train Acc: 0.6504 | Train F1-Macro: 0.6503\n",
            "Epoch 48 | Validation Loss: 0.698383 | Validation Acc: 0.5813 | Validation F1-Macro: 0.5739\n",
            ".........................................................................................\n",
            "Epoch 49 | Train Loss: 0.629955 | Train Acc: 0.6504 | Train F1-Macro: 0.6504\n",
            "Epoch 49 | Validation Loss: 0.700036 | Validation Acc: 0.5813 | Validation F1-Macro: 0.5716\n",
            ".........................................................................................\n",
            "Epoch 50 | Train Loss: 0.618738 | Train Acc: 0.6582 | Train F1-Macro: 0.6582\n",
            "Epoch 50 | Validation Loss: 0.696931 | Validation Acc: 0.5844 | Validation F1-Macro: 0.5774\n",
            ".........................................................................................\n",
            "Test Accuracy: 0.5493\n",
            "Test F1-Macro: 0.5492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_obj = Train(embed_dim=300, pretrained_embeddings=True, epoch=50, lr=0.0001, dropout=0.5, weight_decay=0.00001, filter_sizes=[3, 4, 5], num_filters=[100, 100, 100])\n",
        "model = train_obj.train_model(device, train_dataloader, val_dataloader)\n",
        "test_model(model, device, test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nAtlyNkhdRA",
        "outputId": "f03b95d9-3c5a-4979-e465-2cc70722f359"
      },
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using pretrained embedding\n",
            "Start training...\n",
            "\n",
            "Epoch  1 | Train Loss: 1.123897 | Train Acc: 0.4832 | Train F1-Macro: 0.4785\n",
            "Epoch  1 | Validation Loss: 0.749533 | Validation Acc: 0.4594 | Validation F1-Macro: 0.4485\n",
            ".........................................................................................\n",
            "Epoch  2 | Train Loss: 1.086716 | Train Acc: 0.4779 | Train F1-Macro: 0.4775\n",
            "Epoch  2 | Validation Loss: 0.777291 | Validation Acc: 0.4750 | Validation F1-Macro: 0.4649\n",
            ".........................................................................................\n",
            "Epoch  3 | Train Loss: 1.073144 | Train Acc: 0.4886 | Train F1-Macro: 0.4883\n",
            "Epoch  3 | Validation Loss: 0.773877 | Validation Acc: 0.4750 | Validation F1-Macro: 0.4649\n",
            ".........................................................................................\n",
            "Epoch  4 | Train Loss: 1.003707 | Train Acc: 0.5093 | Train F1-Macro: 0.5087\n",
            "Epoch  4 | Validation Loss: 0.767104 | Validation Acc: 0.5062 | Validation F1-Macro: 0.5047\n",
            ".........................................................................................\n",
            "Epoch  5 | Train Loss: 0.996671 | Train Acc: 0.5018 | Train F1-Macro: 0.5018\n",
            "Epoch  5 | Validation Loss: 0.766820 | Validation Acc: 0.4719 | Validation F1-Macro: 0.4647\n",
            ".........................................................................................\n",
            "Epoch  6 | Train Loss: 0.991213 | Train Acc: 0.5229 | Train F1-Macro: 0.5228\n",
            "Epoch  6 | Validation Loss: 0.765968 | Validation Acc: 0.4750 | Validation F1-Macro: 0.4675\n",
            ".........................................................................................\n",
            "Epoch  7 | Train Loss: 0.991719 | Train Acc: 0.5218 | Train F1-Macro: 0.5212\n",
            "Epoch  7 | Validation Loss: 0.757612 | Validation Acc: 0.5094 | Validation F1-Macro: 0.5091\n",
            ".........................................................................................\n",
            "Epoch  8 | Train Loss: 0.997724 | Train Acc: 0.5257 | Train F1-Macro: 0.5256\n",
            "Epoch  8 | Validation Loss: 0.755828 | Validation Acc: 0.4750 | Validation F1-Macro: 0.4729\n",
            ".........................................................................................\n",
            "Epoch  9 | Train Loss: 0.949164 | Train Acc: 0.5225 | Train F1-Macro: 0.5225\n",
            "Epoch  9 | Validation Loss: 0.755173 | Validation Acc: 0.4750 | Validation F1-Macro: 0.4720\n",
            ".........................................................................................\n",
            "Epoch 10 | Train Loss: 0.971871 | Train Acc: 0.5057 | Train F1-Macro: 0.5055\n",
            "Epoch 10 | Validation Loss: 0.751369 | Validation Acc: 0.4875 | Validation F1-Macro: 0.4865\n",
            ".........................................................................................\n",
            "Epoch 11 | Train Loss: 0.940342 | Train Acc: 0.5329 | Train F1-Macro: 0.5327\n",
            "Epoch 11 | Validation Loss: 0.748886 | Validation Acc: 0.4906 | Validation F1-Macro: 0.4902\n",
            ".........................................................................................\n",
            "Epoch 12 | Train Loss: 0.937362 | Train Acc: 0.5482 | Train F1-Macro: 0.5482\n",
            "Epoch 12 | Validation Loss: 0.750171 | Validation Acc: 0.4688 | Validation F1-Macro: 0.4667\n",
            ".........................................................................................\n",
            "Epoch 13 | Train Loss: 0.901412 | Train Acc: 0.5482 | Train F1-Macro: 0.5480\n",
            "Epoch 13 | Validation Loss: 0.747323 | Validation Acc: 0.4938 | Validation F1-Macro: 0.4934\n",
            ".........................................................................................\n",
            "Epoch 14 | Train Loss: 0.912120 | Train Acc: 0.5404 | Train F1-Macro: 0.5403\n",
            "Epoch 14 | Validation Loss: 0.744683 | Validation Acc: 0.4750 | Validation F1-Macro: 0.4737\n",
            ".........................................................................................\n",
            "Epoch 15 | Train Loss: 0.925079 | Train Acc: 0.5332 | Train F1-Macro: 0.5332\n",
            "Epoch 15 | Validation Loss: 0.744734 | Validation Acc: 0.4750 | Validation F1-Macro: 0.4737\n",
            ".........................................................................................\n",
            "Epoch 16 | Train Loss: 0.880782 | Train Acc: 0.5479 | Train F1-Macro: 0.5478\n",
            "Epoch 16 | Validation Loss: 0.740002 | Validation Acc: 0.5031 | Validation F1-Macro: 0.5031\n",
            ".........................................................................................\n",
            "Epoch 17 | Train Loss: 0.897727 | Train Acc: 0.5379 | Train F1-Macro: 0.5378\n",
            "Epoch 17 | Validation Loss: 0.739631 | Validation Acc: 0.5031 | Validation F1-Macro: 0.5031\n",
            ".........................................................................................\n",
            "Epoch 18 | Train Loss: 0.875631 | Train Acc: 0.5432 | Train F1-Macro: 0.5432\n",
            "Epoch 18 | Validation Loss: 0.737413 | Validation Acc: 0.4844 | Validation F1-Macro: 0.4838\n",
            ".........................................................................................\n",
            "Epoch 19 | Train Loss: 0.856902 | Train Acc: 0.5532 | Train F1-Macro: 0.5532\n",
            "Epoch 19 | Validation Loss: 0.737733 | Validation Acc: 0.4844 | Validation F1-Macro: 0.4838\n",
            ".........................................................................................\n",
            "Epoch 20 | Train Loss: 0.843037 | Train Acc: 0.5700 | Train F1-Macro: 0.5699\n",
            "Epoch 20 | Validation Loss: 0.734266 | Validation Acc: 0.4875 | Validation F1-Macro: 0.4874\n",
            ".........................................................................................\n",
            "Epoch 21 | Train Loss: 0.856208 | Train Acc: 0.5486 | Train F1-Macro: 0.5486\n",
            "Epoch 21 | Validation Loss: 0.733362 | Validation Acc: 0.4750 | Validation F1-Macro: 0.4748\n",
            ".........................................................................................\n",
            "Epoch 22 | Train Loss: 0.853978 | Train Acc: 0.5521 | Train F1-Macro: 0.5521\n",
            "Epoch 22 | Validation Loss: 0.732300 | Validation Acc: 0.4875 | Validation F1-Macro: 0.4875\n",
            ".........................................................................................\n",
            "Epoch 23 | Train Loss: 0.862064 | Train Acc: 0.5564 | Train F1-Macro: 0.5564\n",
            "Epoch 23 | Validation Loss: 0.732162 | Validation Acc: 0.4813 | Validation F1-Macro: 0.4807\n",
            ".........................................................................................\n",
            "Epoch 24 | Train Loss: 0.831756 | Train Acc: 0.5550 | Train F1-Macro: 0.5545\n",
            "Epoch 24 | Validation Loss: 0.729706 | Validation Acc: 0.5219 | Validation F1-Macro: 0.5198\n",
            ".........................................................................................\n",
            "Epoch 25 | Train Loss: 0.839422 | Train Acc: 0.5514 | Train F1-Macro: 0.5514\n",
            "Epoch 25 | Validation Loss: 0.728741 | Validation Acc: 0.4906 | Validation F1-Macro: 0.4905\n",
            ".........................................................................................\n",
            "Epoch 26 | Train Loss: 0.815671 | Train Acc: 0.5829 | Train F1-Macro: 0.5829\n",
            "Epoch 26 | Validation Loss: 0.726607 | Validation Acc: 0.4844 | Validation F1-Macro: 0.4841\n",
            ".........................................................................................\n",
            "Epoch 27 | Train Loss: 0.839134 | Train Acc: 0.5511 | Train F1-Macro: 0.5510\n",
            "Epoch 27 | Validation Loss: 0.725919 | Validation Acc: 0.5094 | Validation F1-Macro: 0.5083\n",
            ".........................................................................................\n",
            "Epoch 28 | Train Loss: 0.822069 | Train Acc: 0.5489 | Train F1-Macro: 0.5489\n",
            "Epoch 28 | Validation Loss: 0.724417 | Validation Acc: 0.4906 | Validation F1-Macro: 0.4905\n",
            ".........................................................................................\n",
            "Epoch 29 | Train Loss: 0.796175 | Train Acc: 0.5814 | Train F1-Macro: 0.5813\n",
            "Epoch 29 | Validation Loss: 0.725083 | Validation Acc: 0.5219 | Validation F1-Macro: 0.5198\n",
            ".........................................................................................\n",
            "Epoch 30 | Train Loss: 0.793635 | Train Acc: 0.5732 | Train F1-Macro: 0.5732\n",
            "Epoch 30 | Validation Loss: 0.723306 | Validation Acc: 0.5344 | Validation F1-Macro: 0.5320\n",
            ".........................................................................................\n",
            "Epoch 31 | Train Loss: 0.800138 | Train Acc: 0.5600 | Train F1-Macro: 0.5600\n",
            "Epoch 31 | Validation Loss: 0.721612 | Validation Acc: 0.4844 | Validation F1-Macro: 0.4841\n",
            ".........................................................................................\n",
            "Epoch 32 | Train Loss: 0.775425 | Train Acc: 0.5811 | Train F1-Macro: 0.5811\n",
            "Epoch 32 | Validation Loss: 0.720593 | Validation Acc: 0.4969 | Validation F1-Macro: 0.4966\n",
            ".........................................................................................\n",
            "Epoch 33 | Train Loss: 0.785103 | Train Acc: 0.5771 | Train F1-Macro: 0.5771\n",
            "Epoch 33 | Validation Loss: 0.719398 | Validation Acc: 0.5219 | Validation F1-Macro: 0.5194\n",
            ".........................................................................................\n",
            "Epoch 34 | Train Loss: 0.788433 | Train Acc: 0.5729 | Train F1-Macro: 0.5728\n",
            "Epoch 34 | Validation Loss: 0.718870 | Validation Acc: 0.5281 | Validation F1-Macro: 0.5247\n",
            ".........................................................................................\n",
            "Epoch 35 | Train Loss: 0.767499 | Train Acc: 0.5754 | Train F1-Macro: 0.5753\n",
            "Epoch 35 | Validation Loss: 0.717002 | Validation Acc: 0.4906 | Validation F1-Macro: 0.4904\n",
            ".........................................................................................\n",
            "Epoch 36 | Train Loss: 0.747086 | Train Acc: 0.6018 | Train F1-Macro: 0.6018\n",
            "Epoch 36 | Validation Loss: 0.716207 | Validation Acc: 0.5000 | Validation F1-Macro: 0.4993\n",
            ".........................................................................................\n",
            "Epoch 37 | Train Loss: 0.773260 | Train Acc: 0.5743 | Train F1-Macro: 0.5743\n",
            "Epoch 37 | Validation Loss: 0.715641 | Validation Acc: 0.5344 | Validation F1-Macro: 0.5315\n",
            ".........................................................................................\n",
            "Epoch 38 | Train Loss: 0.761183 | Train Acc: 0.5804 | Train F1-Macro: 0.5803\n",
            "Epoch 38 | Validation Loss: 0.714738 | Validation Acc: 0.4969 | Validation F1-Macro: 0.4960\n",
            ".........................................................................................\n",
            "Epoch 39 | Train Loss: 0.754597 | Train Acc: 0.5871 | Train F1-Macro: 0.5871\n",
            "Epoch 39 | Validation Loss: 0.713994 | Validation Acc: 0.4969 | Validation F1-Macro: 0.4960\n",
            ".........................................................................................\n",
            "Epoch 40 | Train Loss: 0.748251 | Train Acc: 0.5900 | Train F1-Macro: 0.5899\n",
            "Epoch 40 | Validation Loss: 0.714010 | Validation Acc: 0.5250 | Validation F1-Macro: 0.5213\n",
            ".........................................................................................\n",
            "Epoch 41 | Train Loss: 0.729885 | Train Acc: 0.5854 | Train F1-Macro: 0.5854\n",
            "Epoch 41 | Validation Loss: 0.712552 | Validation Acc: 0.5219 | Validation F1-Macro: 0.5179\n",
            ".........................................................................................\n",
            "Epoch 42 | Train Loss: 0.709411 | Train Acc: 0.6032 | Train F1-Macro: 0.6032\n",
            "Epoch 42 | Validation Loss: 0.711672 | Validation Acc: 0.5219 | Validation F1-Macro: 0.5179\n",
            ".........................................................................................\n",
            "Epoch 43 | Train Loss: 0.749531 | Train Acc: 0.5793 | Train F1-Macro: 0.5792\n",
            "Epoch 43 | Validation Loss: 0.710905 | Validation Acc: 0.5125 | Validation F1-Macro: 0.5113\n",
            ".........................................................................................\n",
            "Epoch 44 | Train Loss: 0.747030 | Train Acc: 0.5768 | Train F1-Macro: 0.5767\n",
            "Epoch 44 | Validation Loss: 0.712735 | Validation Acc: 0.5188 | Validation F1-Macro: 0.5111\n",
            ".........................................................................................\n",
            "Epoch 45 | Train Loss: 0.716731 | Train Acc: 0.6018 | Train F1-Macro: 0.6018\n",
            "Epoch 45 | Validation Loss: 0.710227 | Validation Acc: 0.5125 | Validation F1-Macro: 0.5102\n",
            ".........................................................................................\n",
            "Epoch 46 | Train Loss: 0.737459 | Train Acc: 0.5843 | Train F1-Macro: 0.5843\n",
            "Epoch 46 | Validation Loss: 0.709104 | Validation Acc: 0.5094 | Validation F1-Macro: 0.5086\n",
            ".........................................................................................\n",
            "Epoch 47 | Train Loss: 0.710222 | Train Acc: 0.6132 | Train F1-Macro: 0.6132\n",
            "Epoch 47 | Validation Loss: 0.710192 | Validation Acc: 0.5219 | Validation F1-Macro: 0.5131\n",
            ".........................................................................................\n",
            "Epoch 48 | Train Loss: 0.697916 | Train Acc: 0.6104 | Train F1-Macro: 0.6103\n",
            "Epoch 48 | Validation Loss: 0.709114 | Validation Acc: 0.5312 | Validation F1-Macro: 0.5265\n",
            ".........................................................................................\n",
            "Epoch 49 | Train Loss: 0.735517 | Train Acc: 0.5889 | Train F1-Macro: 0.5889\n",
            "Epoch 49 | Validation Loss: 0.708200 | Validation Acc: 0.5188 | Validation F1-Macro: 0.5111\n",
            ".........................................................................................\n",
            "Epoch 50 | Train Loss: 0.714871 | Train Acc: 0.6093 | Train F1-Macro: 0.6093\n",
            "Epoch 50 | Validation Loss: 0.706448 | Validation Acc: 0.5062 | Validation F1-Macro: 0.5043\n",
            ".........................................................................................\n",
            "Test Accuracy: 0.5573\n",
            "Test F1-Macro: 0.5573\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_obj = Train(embed_dim=300, pretrained_embeddings=True, epoch=50, lr=0.001, dropout=0.2, weight_decay=0.000001, filter_sizes=[3, 3, 4, 5], num_filters=[100, 100, 100, 100])\n",
        "model = train_obj.train_model(device, train_dataloader, val_dataloader)\n",
        "test_model(model, device, test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTgVCeEsuWlT",
        "outputId": "0c7ee93a-01dd-4e34-d0b1-2021e49ed3f4"
      },
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using pretrained embedding\n",
            "Start training...\n",
            "\n",
            "Epoch  1 | Train Loss: 0.843791 | Train Acc: 0.5029 | Train F1-Macro: 0.5023\n",
            "Epoch  1 | Validation Loss: 0.720807 | Validation Acc: 0.5594 | Validation F1-Macro: 0.5567\n",
            ".........................................................................................\n",
            "Epoch  2 | Train Loss: 0.773019 | Train Acc: 0.5379 | Train F1-Macro: 0.5378\n",
            "Epoch  2 | Validation Loss: 0.747739 | Validation Acc: 0.5375 | Validation F1-Macro: 0.5195\n",
            ".........................................................................................\n",
            "Epoch  3 | Train Loss: 0.710534 | Train Acc: 0.5889 | Train F1-Macro: 0.5889\n",
            "Epoch  3 | Validation Loss: 0.719392 | Validation Acc: 0.5938 | Validation F1-Macro: 0.5932\n",
            ".........................................................................................\n",
            "Epoch  4 | Train Loss: 0.687980 | Train Acc: 0.6200 | Train F1-Macro: 0.6200\n",
            "Epoch  4 | Validation Loss: 0.734322 | Validation Acc: 0.5250 | Validation F1-Macro: 0.5077\n",
            ".........................................................................................\n",
            "Epoch  5 | Train Loss: 0.654684 | Train Acc: 0.6311 | Train F1-Macro: 0.6310\n",
            "Epoch  5 | Validation Loss: 0.720030 | Validation Acc: 0.5406 | Validation F1-Macro: 0.5266\n",
            ".........................................................................................\n",
            "Epoch  6 | Train Loss: 0.630485 | Train Acc: 0.6557 | Train F1-Macro: 0.6557\n",
            "Epoch  6 | Validation Loss: 0.706153 | Validation Acc: 0.5656 | Validation F1-Macro: 0.5610\n",
            ".........................................................................................\n",
            "Epoch  7 | Train Loss: 0.589935 | Train Acc: 0.6911 | Train F1-Macro: 0.6911\n",
            "Epoch  7 | Validation Loss: 0.705104 | Validation Acc: 0.5625 | Validation F1-Macro: 0.5556\n",
            ".........................................................................................\n",
            "Epoch  8 | Train Loss: 0.574748 | Train Acc: 0.7011 | Train F1-Macro: 0.7011\n",
            "Epoch  8 | Validation Loss: 0.744629 | Validation Acc: 0.5375 | Validation F1-Macro: 0.4938\n",
            ".........................................................................................\n",
            "Epoch  9 | Train Loss: 0.550025 | Train Acc: 0.7200 | Train F1-Macro: 0.7199\n",
            "Epoch  9 | Validation Loss: 0.694985 | Validation Acc: 0.5875 | Validation F1-Macro: 0.5859\n",
            ".........................................................................................\n",
            "Epoch 10 | Train Loss: 0.538616 | Train Acc: 0.7293 | Train F1-Macro: 0.7292\n",
            "Epoch 10 | Validation Loss: 0.695300 | Validation Acc: 0.5750 | Validation F1-Macro: 0.5726\n",
            ".........................................................................................\n",
            "Epoch 11 | Train Loss: 0.504322 | Train Acc: 0.7500 | Train F1-Macro: 0.7500\n",
            "Epoch 11 | Validation Loss: 0.698631 | Validation Acc: 0.5906 | Validation F1-Macro: 0.5824\n",
            ".........................................................................................\n",
            "Epoch 12 | Train Loss: 0.499385 | Train Acc: 0.7618 | Train F1-Macro: 0.7618\n",
            "Epoch 12 | Validation Loss: 0.691851 | Validation Acc: 0.5875 | Validation F1-Macro: 0.5859\n",
            ".........................................................................................\n",
            "Epoch 13 | Train Loss: 0.480302 | Train Acc: 0.7764 | Train F1-Macro: 0.7764\n",
            "Epoch 13 | Validation Loss: 0.695734 | Validation Acc: 0.5875 | Validation F1-Macro: 0.5833\n",
            ".........................................................................................\n",
            "Epoch 14 | Train Loss: 0.453870 | Train Acc: 0.7932 | Train F1-Macro: 0.7932\n",
            "Epoch 14 | Validation Loss: 0.734345 | Validation Acc: 0.5625 | Validation F1-Macro: 0.5333\n",
            ".........................................................................................\n",
            "Epoch 15 | Train Loss: 0.446764 | Train Acc: 0.7982 | Train F1-Macro: 0.7982\n",
            "Epoch 15 | Validation Loss: 0.691594 | Validation Acc: 0.5781 | Validation F1-Macro: 0.5781\n",
            ".........................................................................................\n",
            "Epoch 16 | Train Loss: 0.439044 | Train Acc: 0.8032 | Train F1-Macro: 0.8032\n",
            "Epoch 16 | Validation Loss: 0.712333 | Validation Acc: 0.6031 | Validation F1-Macro: 0.5901\n",
            ".........................................................................................\n",
            "Epoch 17 | Train Loss: 0.423929 | Train Acc: 0.8168 | Train F1-Macro: 0.8168\n",
            "Epoch 17 | Validation Loss: 0.721149 | Validation Acc: 0.5938 | Validation F1-Macro: 0.5757\n",
            ".........................................................................................\n",
            "Epoch 18 | Train Loss: 0.416824 | Train Acc: 0.8218 | Train F1-Macro: 0.8218\n",
            "Epoch 18 | Validation Loss: 0.698050 | Validation Acc: 0.5938 | Validation F1-Macro: 0.5918\n",
            ".........................................................................................\n",
            "Epoch 19 | Train Loss: 0.403393 | Train Acc: 0.8239 | Train F1-Macro: 0.8239\n",
            "Epoch 19 | Validation Loss: 0.704640 | Validation Acc: 0.5969 | Validation F1-Macro: 0.5895\n",
            ".........................................................................................\n",
            "Epoch 20 | Train Loss: 0.372111 | Train Acc: 0.8457 | Train F1-Macro: 0.8457\n",
            "Epoch 20 | Validation Loss: 0.711076 | Validation Acc: 0.6062 | Validation F1-Macro: 0.5964\n",
            ".........................................................................................\n",
            "Epoch 21 | Train Loss: 0.375742 | Train Acc: 0.8479 | Train F1-Macro: 0.8479\n",
            "Epoch 21 | Validation Loss: 0.704862 | Validation Acc: 0.5969 | Validation F1-Macro: 0.5935\n",
            ".........................................................................................\n",
            "Epoch 22 | Train Loss: 0.363528 | Train Acc: 0.8579 | Train F1-Macro: 0.8579\n",
            "Epoch 22 | Validation Loss: 0.706283 | Validation Acc: 0.6094 | Validation F1-Macro: 0.6066\n",
            ".........................................................................................\n",
            "Epoch 23 | Train Loss: 0.353794 | Train Acc: 0.8564 | Train F1-Macro: 0.8564\n",
            "Epoch 23 | Validation Loss: 0.705634 | Validation Acc: 0.5938 | Validation F1-Macro: 0.5935\n",
            ".........................................................................................\n",
            "Epoch 24 | Train Loss: 0.339034 | Train Acc: 0.8704 | Train F1-Macro: 0.8703\n",
            "Epoch 24 | Validation Loss: 0.707203 | Validation Acc: 0.6062 | Validation F1-Macro: 0.6055\n",
            ".........................................................................................\n",
            "Epoch 25 | Train Loss: 0.327333 | Train Acc: 0.8739 | Train F1-Macro: 0.8739\n",
            "Epoch 25 | Validation Loss: 0.713572 | Validation Acc: 0.5969 | Validation F1-Macro: 0.5931\n",
            ".........................................................................................\n",
            "Epoch 26 | Train Loss: 0.327494 | Train Acc: 0.8771 | Train F1-Macro: 0.8771\n",
            "Epoch 26 | Validation Loss: 0.720368 | Validation Acc: 0.5906 | Validation F1-Macro: 0.5845\n",
            ".........................................................................................\n",
            "Epoch 27 | Train Loss: 0.306695 | Train Acc: 0.8914 | Train F1-Macro: 0.8914\n",
            "Epoch 27 | Validation Loss: 0.713733 | Validation Acc: 0.6062 | Validation F1-Macro: 0.6053\n",
            ".........................................................................................\n",
            "Epoch 28 | Train Loss: 0.294247 | Train Acc: 0.8968 | Train F1-Macro: 0.8968\n",
            "Epoch 28 | Validation Loss: 0.734550 | Validation Acc: 0.6000 | Validation F1-Macro: 0.5937\n",
            ".........................................................................................\n",
            "Epoch 29 | Train Loss: 0.285574 | Train Acc: 0.8932 | Train F1-Macro: 0.8932\n",
            "Epoch 29 | Validation Loss: 0.727687 | Validation Acc: 0.5969 | Validation F1-Macro: 0.5914\n",
            ".........................................................................................\n",
            "Epoch 30 | Train Loss: 0.280154 | Train Acc: 0.9046 | Train F1-Macro: 0.9046\n",
            "Epoch 30 | Validation Loss: 0.721389 | Validation Acc: 0.5906 | Validation F1-Macro: 0.5899\n",
            ".........................................................................................\n",
            "Epoch 31 | Train Loss: 0.263872 | Train Acc: 0.9114 | Train F1-Macro: 0.9114\n",
            "Epoch 31 | Validation Loss: 0.734612 | Validation Acc: 0.5969 | Validation F1-Macro: 0.5920\n",
            ".........................................................................................\n",
            "Epoch 32 | Train Loss: 0.268646 | Train Acc: 0.9096 | Train F1-Macro: 0.9096\n",
            "Epoch 32 | Validation Loss: 0.724129 | Validation Acc: 0.5906 | Validation F1-Macro: 0.5895\n",
            ".........................................................................................\n",
            "Epoch 33 | Train Loss: 0.253898 | Train Acc: 0.9182 | Train F1-Macro: 0.9182\n",
            "Epoch 33 | Validation Loss: 0.732561 | Validation Acc: 0.5813 | Validation F1-Macro: 0.5807\n",
            ".........................................................................................\n",
            "Epoch 34 | Train Loss: 0.253217 | Train Acc: 0.9175 | Train F1-Macro: 0.9175\n",
            "Epoch 34 | Validation Loss: 0.728407 | Validation Acc: 0.5969 | Validation F1-Macro: 0.5960\n",
            ".........................................................................................\n",
            "Epoch 35 | Train Loss: 0.236958 | Train Acc: 0.9232 | Train F1-Macro: 0.9232\n",
            "Epoch 35 | Validation Loss: 0.734264 | Validation Acc: 0.6000 | Validation F1-Macro: 0.5977\n",
            ".........................................................................................\n",
            "Epoch 36 | Train Loss: 0.240066 | Train Acc: 0.9204 | Train F1-Macro: 0.9204\n",
            "Epoch 36 | Validation Loss: 0.732096 | Validation Acc: 0.5938 | Validation F1-Macro: 0.5927\n",
            ".........................................................................................\n",
            "Epoch 37 | Train Loss: 0.234133 | Train Acc: 0.9257 | Train F1-Macro: 0.9257\n",
            "Epoch 37 | Validation Loss: 0.737456 | Validation Acc: 0.5906 | Validation F1-Macro: 0.5899\n",
            ".........................................................................................\n",
            "Epoch 38 | Train Loss: 0.214160 | Train Acc: 0.9339 | Train F1-Macro: 0.9339\n",
            "Epoch 38 | Validation Loss: 0.741371 | Validation Acc: 0.5844 | Validation F1-Macro: 0.5835\n",
            ".........................................................................................\n",
            "Epoch 39 | Train Loss: 0.209634 | Train Acc: 0.9318 | Train F1-Macro: 0.9318\n",
            "Epoch 39 | Validation Loss: 0.737153 | Validation Acc: 0.5813 | Validation F1-Macro: 0.5812\n",
            ".........................................................................................\n",
            "Epoch 40 | Train Loss: 0.213318 | Train Acc: 0.9293 | Train F1-Macro: 0.9293\n",
            "Epoch 40 | Validation Loss: 0.745016 | Validation Acc: 0.5687 | Validation F1-Macro: 0.5681\n",
            ".........................................................................................\n",
            "Epoch 41 | Train Loss: 0.203804 | Train Acc: 0.9386 | Train F1-Macro: 0.9386\n",
            "Epoch 41 | Validation Loss: 0.744372 | Validation Acc: 0.5875 | Validation F1-Macro: 0.5874\n",
            ".........................................................................................\n",
            "Epoch 42 | Train Loss: 0.194748 | Train Acc: 0.9429 | Train F1-Macro: 0.9429\n",
            "Epoch 42 | Validation Loss: 0.746902 | Validation Acc: 0.5875 | Validation F1-Macro: 0.5875\n",
            ".........................................................................................\n",
            "Epoch 43 | Train Loss: 0.190824 | Train Acc: 0.9457 | Train F1-Macro: 0.9457\n",
            "Epoch 43 | Validation Loss: 0.747222 | Validation Acc: 0.5875 | Validation F1-Macro: 0.5874\n",
            ".........................................................................................\n",
            "Epoch 44 | Train Loss: 0.186224 | Train Acc: 0.9454 | Train F1-Macro: 0.9454\n",
            "Epoch 44 | Validation Loss: 0.760316 | Validation Acc: 0.5594 | Validation F1-Macro: 0.5593\n",
            ".........................................................................................\n",
            "Epoch 45 | Train Loss: 0.190485 | Train Acc: 0.9432 | Train F1-Macro: 0.9432\n",
            "Epoch 45 | Validation Loss: 0.755030 | Validation Acc: 0.5906 | Validation F1-Macro: 0.5904\n",
            ".........................................................................................\n",
            "Epoch 46 | Train Loss: 0.181459 | Train Acc: 0.9461 | Train F1-Macro: 0.9461\n",
            "Epoch 46 | Validation Loss: 0.755528 | Validation Acc: 0.5844 | Validation F1-Macro: 0.5843\n",
            ".........................................................................................\n",
            "Epoch 47 | Train Loss: 0.167854 | Train Acc: 0.9564 | Train F1-Macro: 0.9564\n",
            "Epoch 47 | Validation Loss: 0.763496 | Validation Acc: 0.5719 | Validation F1-Macro: 0.5712\n",
            ".........................................................................................\n",
            "Epoch 48 | Train Loss: 0.168499 | Train Acc: 0.9550 | Train F1-Macro: 0.9550\n",
            "Epoch 48 | Validation Loss: 0.762380 | Validation Acc: 0.5875 | Validation F1-Macro: 0.5875\n",
            ".........................................................................................\n",
            "Epoch 49 | Train Loss: 0.163345 | Train Acc: 0.9486 | Train F1-Macro: 0.9486\n",
            "Epoch 49 | Validation Loss: 0.765585 | Validation Acc: 0.5938 | Validation F1-Macro: 0.5937\n",
            ".........................................................................................\n",
            "Epoch 50 | Train Loss: 0.170192 | Train Acc: 0.9457 | Train F1-Macro: 0.9457\n",
            "Epoch 50 | Validation Loss: 0.761291 | Validation Acc: 0.5844 | Validation F1-Macro: 0.5843\n",
            ".........................................................................................\n",
            "Test Accuracy: 0.5484\n",
            "Test F1-Macro: 0.5394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_obj = Train(embed_dim=300, pretrained_embeddings=True, epoch=50, lr=0.0001, dropout=0.5, weight_decay=0.001, filter_sizes=[3, 3, 4, 4, 5], num_filters=[100, 100, 100, 100, 100])\n",
        "model = train_obj.train_model(device, train_dataloader, val_dataloader)\n",
        "test_model(model, device, test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHKYHgzsyUub",
        "outputId": "f3dc3678-146f-4410-afbe-87683bf103da"
      },
      "execution_count": 317,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using pretrained embedding\n",
            "Start training...\n",
            "\n",
            "Epoch  1 | Train Loss: 1.094573 | Train Acc: 0.5136 | Train F1-Macro: 0.5129\n",
            "Epoch  1 | Validation Loss: 0.670389 | Validation Acc: 0.6094 | Validation F1-Macro: 0.6077\n",
            ".........................................................................................\n",
            "Epoch  2 | Train Loss: 1.071044 | Train Acc: 0.5129 | Train F1-Macro: 0.5128\n",
            "Epoch  2 | Validation Loss: 0.671768 | Validation Acc: 0.6188 | Validation F1-Macro: 0.6182\n",
            ".........................................................................................\n",
            "Epoch  3 | Train Loss: 1.059534 | Train Acc: 0.5129 | Train F1-Macro: 0.5129\n",
            "Epoch  3 | Validation Loss: 0.669888 | Validation Acc: 0.6250 | Validation F1-Macro: 0.6249\n",
            ".........................................................................................\n",
            "Epoch  4 | Train Loss: 1.023768 | Train Acc: 0.5179 | Train F1-Macro: 0.5176\n",
            "Epoch  4 | Validation Loss: 0.670363 | Validation Acc: 0.6125 | Validation F1-Macro: 0.6115\n",
            ".........................................................................................\n",
            "Epoch  5 | Train Loss: 1.012131 | Train Acc: 0.5182 | Train F1-Macro: 0.5182\n",
            "Epoch  5 | Validation Loss: 0.667448 | Validation Acc: 0.6062 | Validation F1-Macro: 0.6057\n",
            ".........................................................................................\n",
            "Epoch  6 | Train Loss: 1.016847 | Train Acc: 0.5125 | Train F1-Macro: 0.5123\n",
            "Epoch  6 | Validation Loss: 0.667201 | Validation Acc: 0.6156 | Validation F1-Macro: 0.6140\n",
            ".........................................................................................\n",
            "Epoch  7 | Train Loss: 0.973698 | Train Acc: 0.5296 | Train F1-Macro: 0.5296\n",
            "Epoch  7 | Validation Loss: 0.665581 | Validation Acc: 0.6031 | Validation F1-Macro: 0.6020\n",
            ".........................................................................................\n",
            "Epoch  8 | Train Loss: 0.939409 | Train Acc: 0.5421 | Train F1-Macro: 0.5421\n",
            "Epoch  8 | Validation Loss: 0.664626 | Validation Acc: 0.6188 | Validation F1-Macro: 0.6182\n",
            ".........................................................................................\n",
            "Epoch  9 | Train Loss: 0.975615 | Train Acc: 0.5329 | Train F1-Macro: 0.5328\n",
            "Epoch  9 | Validation Loss: 0.664203 | Validation Acc: 0.6094 | Validation F1-Macro: 0.6085\n",
            ".........................................................................................\n",
            "Epoch 10 | Train Loss: 0.960863 | Train Acc: 0.5221 | Train F1-Macro: 0.5221\n",
            "Epoch 10 | Validation Loss: 0.663803 | Validation Acc: 0.6125 | Validation F1-Macro: 0.6118\n",
            ".........................................................................................\n",
            "Epoch 11 | Train Loss: 0.933999 | Train Acc: 0.5375 | Train F1-Macro: 0.5374\n",
            "Epoch 11 | Validation Loss: 0.664649 | Validation Acc: 0.6062 | Validation F1-Macro: 0.6047\n",
            ".........................................................................................\n",
            "Epoch 12 | Train Loss: 0.940864 | Train Acc: 0.5393 | Train F1-Macro: 0.5393\n",
            "Epoch 12 | Validation Loss: 0.662703 | Validation Acc: 0.6156 | Validation F1-Macro: 0.6150\n",
            ".........................................................................................\n",
            "Epoch 13 | Train Loss: 0.935892 | Train Acc: 0.5418 | Train F1-Macro: 0.5418\n",
            "Epoch 13 | Validation Loss: 0.662012 | Validation Acc: 0.6344 | Validation F1-Macro: 0.6342\n",
            ".........................................................................................\n",
            "Epoch 14 | Train Loss: 0.896853 | Train Acc: 0.5507 | Train F1-Macro: 0.5507\n",
            "Epoch 14 | Validation Loss: 0.662416 | Validation Acc: 0.6281 | Validation F1-Macro: 0.6280\n",
            ".........................................................................................\n",
            "Epoch 15 | Train Loss: 0.871943 | Train Acc: 0.5579 | Train F1-Macro: 0.5579\n",
            "Epoch 15 | Validation Loss: 0.662258 | Validation Acc: 0.6188 | Validation F1-Macro: 0.6185\n",
            ".........................................................................................\n",
            "Epoch 16 | Train Loss: 0.888196 | Train Acc: 0.5432 | Train F1-Macro: 0.5432\n",
            "Epoch 16 | Validation Loss: 0.662256 | Validation Acc: 0.6125 | Validation F1-Macro: 0.6124\n",
            ".........................................................................................\n",
            "Epoch 17 | Train Loss: 0.851381 | Train Acc: 0.5568 | Train F1-Macro: 0.5568\n",
            "Epoch 17 | Validation Loss: 0.661973 | Validation Acc: 0.6219 | Validation F1-Macro: 0.6216\n",
            ".........................................................................................\n",
            "Epoch 18 | Train Loss: 0.866971 | Train Acc: 0.5650 | Train F1-Macro: 0.5650\n",
            "Epoch 18 | Validation Loss: 0.661987 | Validation Acc: 0.6094 | Validation F1-Macro: 0.6080\n",
            ".........................................................................................\n",
            "Epoch 19 | Train Loss: 0.847270 | Train Acc: 0.5729 | Train F1-Macro: 0.5728\n",
            "Epoch 19 | Validation Loss: 0.662061 | Validation Acc: 0.6062 | Validation F1-Macro: 0.6059\n",
            ".........................................................................................\n",
            "Epoch 20 | Train Loss: 0.846962 | Train Acc: 0.5768 | Train F1-Macro: 0.5768\n",
            "Epoch 20 | Validation Loss: 0.661527 | Validation Acc: 0.6094 | Validation F1-Macro: 0.6083\n",
            ".........................................................................................\n",
            "Epoch 21 | Train Loss: 0.823716 | Train Acc: 0.5879 | Train F1-Macro: 0.5878\n",
            "Epoch 21 | Validation Loss: 0.662175 | Validation Acc: 0.6062 | Validation F1-Macro: 0.6059\n",
            ".........................................................................................\n",
            "Epoch 22 | Train Loss: 0.854020 | Train Acc: 0.5789 | Train F1-Macro: 0.5789\n",
            "Epoch 22 | Validation Loss: 0.663885 | Validation Acc: 0.6125 | Validation F1-Macro: 0.6086\n",
            ".........................................................................................\n",
            "Epoch 23 | Train Loss: 0.826156 | Train Acc: 0.5811 | Train F1-Macro: 0.5810\n",
            "Epoch 23 | Validation Loss: 0.661681 | Validation Acc: 0.6094 | Validation F1-Macro: 0.6073\n",
            ".........................................................................................\n",
            "Epoch 24 | Train Loss: 0.843623 | Train Acc: 0.5732 | Train F1-Macro: 0.5732\n",
            "Epoch 24 | Validation Loss: 0.663449 | Validation Acc: 0.6188 | Validation F1-Macro: 0.6144\n",
            ".........................................................................................\n",
            "Epoch 25 | Train Loss: 0.830933 | Train Acc: 0.5761 | Train F1-Macro: 0.5761\n",
            "Epoch 25 | Validation Loss: 0.666385 | Validation Acc: 0.6062 | Validation F1-Macro: 0.5993\n",
            ".........................................................................................\n",
            "Epoch 26 | Train Loss: 0.787252 | Train Acc: 0.5800 | Train F1-Macro: 0.5799\n",
            "Epoch 26 | Validation Loss: 0.662955 | Validation Acc: 0.6094 | Validation F1-Macro: 0.6061\n",
            ".........................................................................................\n",
            "Epoch 27 | Train Loss: 0.813965 | Train Acc: 0.5732 | Train F1-Macro: 0.5732\n",
            "Epoch 27 | Validation Loss: 0.662607 | Validation Acc: 0.6031 | Validation F1-Macro: 0.5994\n",
            ".........................................................................................\n",
            "Epoch 28 | Train Loss: 0.770179 | Train Acc: 0.5936 | Train F1-Macro: 0.5935\n",
            "Epoch 28 | Validation Loss: 0.661474 | Validation Acc: 0.5781 | Validation F1-Macro: 0.5769\n",
            ".........................................................................................\n",
            "Epoch 29 | Train Loss: 0.804470 | Train Acc: 0.5775 | Train F1-Macro: 0.5775\n",
            "Epoch 29 | Validation Loss: 0.661007 | Validation Acc: 0.5906 | Validation F1-Macro: 0.5906\n",
            ".........................................................................................\n",
            "Epoch 30 | Train Loss: 0.801143 | Train Acc: 0.5921 | Train F1-Macro: 0.5921\n",
            "Epoch 30 | Validation Loss: 0.661014 | Validation Acc: 0.5906 | Validation F1-Macro: 0.5906\n",
            ".........................................................................................\n",
            "Epoch 31 | Train Loss: 0.810565 | Train Acc: 0.5818 | Train F1-Macro: 0.5817\n",
            "Epoch 31 | Validation Loss: 0.660935 | Validation Acc: 0.5813 | Validation F1-Macro: 0.5812\n",
            ".........................................................................................\n",
            "Epoch 32 | Train Loss: 0.776084 | Train Acc: 0.5789 | Train F1-Macro: 0.5789\n",
            "Epoch 32 | Validation Loss: 0.660379 | Validation Acc: 0.5875 | Validation F1-Macro: 0.5871\n",
            ".........................................................................................\n",
            "Epoch 33 | Train Loss: 0.762165 | Train Acc: 0.5882 | Train F1-Macro: 0.5881\n",
            "Epoch 33 | Validation Loss: 0.661167 | Validation Acc: 0.5813 | Validation F1-Macro: 0.5796\n",
            ".........................................................................................\n",
            "Epoch 34 | Train Loss: 0.765914 | Train Acc: 0.6046 | Train F1-Macro: 0.6046\n",
            "Epoch 34 | Validation Loss: 0.661420 | Validation Acc: 0.5813 | Validation F1-Macro: 0.5796\n",
            ".........................................................................................\n",
            "Epoch 35 | Train Loss: 0.769936 | Train Acc: 0.5946 | Train F1-Macro: 0.5946\n",
            "Epoch 35 | Validation Loss: 0.660241 | Validation Acc: 0.5875 | Validation F1-Macro: 0.5875\n",
            ".........................................................................................\n",
            "Epoch 36 | Train Loss: 0.756512 | Train Acc: 0.6032 | Train F1-Macro: 0.6032\n",
            "Epoch 36 | Validation Loss: 0.660214 | Validation Acc: 0.5813 | Validation F1-Macro: 0.5808\n",
            ".........................................................................................\n",
            "Epoch 37 | Train Loss: 0.752734 | Train Acc: 0.5996 | Train F1-Macro: 0.5996\n",
            "Epoch 37 | Validation Loss: 0.660662 | Validation Acc: 0.5906 | Validation F1-Macro: 0.5897\n",
            ".........................................................................................\n",
            "Epoch 38 | Train Loss: 0.786335 | Train Acc: 0.5961 | Train F1-Macro: 0.5961\n",
            "Epoch 38 | Validation Loss: 0.660813 | Validation Acc: 0.5906 | Validation F1-Macro: 0.5897\n",
            ".........................................................................................\n",
            "Epoch 39 | Train Loss: 0.736368 | Train Acc: 0.6064 | Train F1-Macro: 0.6064\n",
            "Epoch 39 | Validation Loss: 0.661987 | Validation Acc: 0.5875 | Validation F1-Macro: 0.5855\n",
            ".........................................................................................\n",
            "Epoch 40 | Train Loss: 0.739010 | Train Acc: 0.6021 | Train F1-Macro: 0.6021\n",
            "Epoch 40 | Validation Loss: 0.660537 | Validation Acc: 0.5906 | Validation F1-Macro: 0.5904\n",
            ".........................................................................................\n",
            "Epoch 41 | Train Loss: 0.717267 | Train Acc: 0.6225 | Train F1-Macro: 0.6225\n",
            "Epoch 41 | Validation Loss: 0.660657 | Validation Acc: 0.5906 | Validation F1-Macro: 0.5904\n",
            ".........................................................................................\n",
            "Epoch 42 | Train Loss: 0.741509 | Train Acc: 0.5975 | Train F1-Macro: 0.5975\n",
            "Epoch 42 | Validation Loss: 0.660532 | Validation Acc: 0.5906 | Validation F1-Macro: 0.5904\n",
            ".........................................................................................\n",
            "Epoch 43 | Train Loss: 0.726324 | Train Acc: 0.6204 | Train F1-Macro: 0.6203\n",
            "Epoch 43 | Validation Loss: 0.661130 | Validation Acc: 0.5750 | Validation F1-Macro: 0.5742\n",
            ".........................................................................................\n",
            "Epoch 44 | Train Loss: 0.726491 | Train Acc: 0.6043 | Train F1-Macro: 0.6043\n",
            "Epoch 44 | Validation Loss: 0.661175 | Validation Acc: 0.5969 | Validation F1-Macro: 0.5968\n",
            ".........................................................................................\n",
            "Epoch 45 | Train Loss: 0.731378 | Train Acc: 0.6054 | Train F1-Macro: 0.6054\n",
            "Epoch 45 | Validation Loss: 0.661231 | Validation Acc: 0.5719 | Validation F1-Macro: 0.5712\n",
            ".........................................................................................\n",
            "Epoch 46 | Train Loss: 0.719361 | Train Acc: 0.6204 | Train F1-Macro: 0.6203\n",
            "Epoch 46 | Validation Loss: 0.661033 | Validation Acc: 0.5750 | Validation F1-Macro: 0.5749\n",
            ".........................................................................................\n",
            "Epoch 47 | Train Loss: 0.701815 | Train Acc: 0.6193 | Train F1-Macro: 0.6193\n",
            "Epoch 47 | Validation Loss: 0.661728 | Validation Acc: 0.5906 | Validation F1-Macro: 0.5895\n",
            ".........................................................................................\n",
            "Epoch 48 | Train Loss: 0.675152 | Train Acc: 0.6432 | Train F1-Macro: 0.6432\n",
            "Epoch 48 | Validation Loss: 0.661943 | Validation Acc: 0.5969 | Validation F1-Macro: 0.5954\n",
            ".........................................................................................\n",
            "Epoch 49 | Train Loss: 0.680383 | Train Acc: 0.6304 | Train F1-Macro: 0.6304\n",
            "Epoch 49 | Validation Loss: 0.662545 | Validation Acc: 0.5969 | Validation F1-Macro: 0.5954\n",
            ".........................................................................................\n",
            "Epoch 50 | Train Loss: 0.698257 | Train Acc: 0.6275 | Train F1-Macro: 0.6275\n",
            "Epoch 50 | Validation Loss: 0.662905 | Validation Acc: 0.5969 | Validation F1-Macro: 0.5954\n",
            ".........................................................................................\n",
            "Test Accuracy: 0.5627\n",
            "Test F1-Macro: 0.5627\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_obj = Train(embed_dim=50, pretrained_embeddings=True, epoch=50, lr=0.0001, dropout=0.2, weight_decay=0.00001, filter_sizes=[3, 3, 4, 5], num_filters=[150, 150, 150, 150])\n",
        "model = train_obj.train_model(device, train_dataloader, val_dataloader)\n",
        "test_model(model, device, test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNFIFcqpuXQe",
        "outputId": "8b286370-87a6-4c9c-8b83-343219a3f301"
      },
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using pretrained embedding\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 399999/400000 [00:13<00:00, 29100.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training...\n",
            "\n",
            "Epoch  1 | Train Loss: 0.914840 | Train Acc: 0.5246 | Train F1-Macro: 0.5131\n",
            "Epoch  1 | Validation Loss: 0.732948 | Validation Acc: 0.5188 | Validation F1-Macro: 0.5178\n",
            ".........................................................................................\n",
            "Epoch  2 | Train Loss: 0.831259 | Train Acc: 0.5193 | Train F1-Macro: 0.5193\n",
            "Epoch  2 | Validation Loss: 0.740124 | Validation Acc: 0.5219 | Validation F1-Macro: 0.5215\n",
            ".........................................................................................\n",
            "Epoch  3 | Train Loss: 0.841616 | Train Acc: 0.5139 | Train F1-Macro: 0.5139\n",
            "Epoch  3 | Validation Loss: 0.739808 | Validation Acc: 0.5094 | Validation F1-Macro: 0.5094\n",
            ".........................................................................................\n",
            "Epoch  4 | Train Loss: 0.814290 | Train Acc: 0.5329 | Train F1-Macro: 0.5328\n",
            "Epoch  4 | Validation Loss: 0.738963 | Validation Acc: 0.5000 | Validation F1-Macro: 0.4998\n",
            ".........................................................................................\n",
            "Epoch  5 | Train Loss: 0.831110 | Train Acc: 0.5189 | Train F1-Macro: 0.5189\n",
            "Epoch  5 | Validation Loss: 0.737259 | Validation Acc: 0.5156 | Validation F1-Macro: 0.5155\n",
            ".........................................................................................\n",
            "Epoch  6 | Train Loss: 0.807122 | Train Acc: 0.5411 | Train F1-Macro: 0.5411\n",
            "Epoch  6 | Validation Loss: 0.737187 | Validation Acc: 0.5219 | Validation F1-Macro: 0.5211\n",
            ".........................................................................................\n",
            "Epoch  7 | Train Loss: 0.822507 | Train Acc: 0.5157 | Train F1-Macro: 0.5157\n",
            "Epoch  7 | Validation Loss: 0.735375 | Validation Acc: 0.5188 | Validation F1-Macro: 0.5181\n",
            ".........................................................................................\n",
            "Epoch  8 | Train Loss: 0.819278 | Train Acc: 0.5282 | Train F1-Macro: 0.5282\n",
            "Epoch  8 | Validation Loss: 0.734638 | Validation Acc: 0.5219 | Validation F1-Macro: 0.5213\n",
            ".........................................................................................\n",
            "Epoch  9 | Train Loss: 0.811273 | Train Acc: 0.5243 | Train F1-Macro: 0.5243\n",
            "Epoch  9 | Validation Loss: 0.732163 | Validation Acc: 0.5188 | Validation F1-Macro: 0.5186\n",
            ".........................................................................................\n",
            "Epoch 10 | Train Loss: 0.801491 | Train Acc: 0.5393 | Train F1-Macro: 0.5393\n",
            "Epoch 10 | Validation Loss: 0.732701 | Validation Acc: 0.5125 | Validation F1-Macro: 0.5122\n",
            ".........................................................................................\n",
            "Epoch 11 | Train Loss: 0.813223 | Train Acc: 0.5300 | Train F1-Macro: 0.5299\n",
            "Epoch 11 | Validation Loss: 0.732171 | Validation Acc: 0.5344 | Validation F1-Macro: 0.5324\n",
            ".........................................................................................\n",
            "Epoch 12 | Train Loss: 0.792807 | Train Acc: 0.5443 | Train F1-Macro: 0.5442\n",
            "Epoch 12 | Validation Loss: 0.731530 | Validation Acc: 0.5344 | Validation F1-Macro: 0.5324\n",
            ".........................................................................................\n",
            "Epoch 13 | Train Loss: 0.800657 | Train Acc: 0.5386 | Train F1-Macro: 0.5385\n",
            "Epoch 13 | Validation Loss: 0.729163 | Validation Acc: 0.5375 | Validation F1-Macro: 0.5357\n",
            ".........................................................................................\n",
            "Epoch 14 | Train Loss: 0.799020 | Train Acc: 0.5461 | Train F1-Macro: 0.5460\n",
            "Epoch 14 | Validation Loss: 0.735329 | Validation Acc: 0.5281 | Validation F1-Macro: 0.5186\n",
            ".........................................................................................\n",
            "Epoch 15 | Train Loss: 0.799992 | Train Acc: 0.5329 | Train F1-Macro: 0.5328\n",
            "Epoch 15 | Validation Loss: 0.730564 | Validation Acc: 0.5312 | Validation F1-Macro: 0.5271\n",
            ".........................................................................................\n",
            "Epoch 16 | Train Loss: 0.800668 | Train Acc: 0.5346 | Train F1-Macro: 0.5345\n",
            "Epoch 16 | Validation Loss: 0.727707 | Validation Acc: 0.5375 | Validation F1-Macro: 0.5353\n",
            ".........................................................................................\n",
            "Epoch 17 | Train Loss: 0.800974 | Train Acc: 0.5193 | Train F1-Macro: 0.5191\n",
            "Epoch 17 | Validation Loss: 0.725853 | Validation Acc: 0.5250 | Validation F1-Macro: 0.5245\n",
            ".........................................................................................\n",
            "Epoch 18 | Train Loss: 0.774195 | Train Acc: 0.5539 | Train F1-Macro: 0.5539\n",
            "Epoch 18 | Validation Loss: 0.726610 | Validation Acc: 0.5344 | Validation F1-Macro: 0.5310\n",
            ".........................................................................................\n",
            "Epoch 19 | Train Loss: 0.788506 | Train Acc: 0.5439 | Train F1-Macro: 0.5439\n",
            "Epoch 19 | Validation Loss: 0.726487 | Validation Acc: 0.5406 | Validation F1-Macro: 0.5368\n",
            ".........................................................................................\n",
            "Epoch 20 | Train Loss: 0.784968 | Train Acc: 0.5418 | Train F1-Macro: 0.5416\n",
            "Epoch 20 | Validation Loss: 0.727446 | Validation Acc: 0.5250 | Validation F1-Macro: 0.5182\n",
            ".........................................................................................\n",
            "Epoch 21 | Train Loss: 0.762298 | Train Acc: 0.5604 | Train F1-Macro: 0.5602\n",
            "Epoch 21 | Validation Loss: 0.724148 | Validation Acc: 0.5344 | Validation F1-Macro: 0.5315\n",
            ".........................................................................................\n",
            "Epoch 22 | Train Loss: 0.778780 | Train Acc: 0.5450 | Train F1-Macro: 0.5449\n",
            "Epoch 22 | Validation Loss: 0.722234 | Validation Acc: 0.5281 | Validation F1-Macro: 0.5261\n",
            ".........................................................................................\n",
            "Epoch 23 | Train Loss: 0.767885 | Train Acc: 0.5436 | Train F1-Macro: 0.5434\n",
            "Epoch 23 | Validation Loss: 0.721416 | Validation Acc: 0.5250 | Validation F1-Macro: 0.5243\n",
            ".........................................................................................\n",
            "Epoch 24 | Train Loss: 0.790176 | Train Acc: 0.5318 | Train F1-Macro: 0.5317\n",
            "Epoch 24 | Validation Loss: 0.719856 | Validation Acc: 0.5281 | Validation F1-Macro: 0.5276\n",
            ".........................................................................................\n",
            "Epoch 25 | Train Loss: 0.771848 | Train Acc: 0.5611 | Train F1-Macro: 0.5609\n",
            "Epoch 25 | Validation Loss: 0.718827 | Validation Acc: 0.5281 | Validation F1-Macro: 0.5276\n",
            ".........................................................................................\n",
            "Epoch 26 | Train Loss: 0.767635 | Train Acc: 0.5518 | Train F1-Macro: 0.5518\n",
            "Epoch 26 | Validation Loss: 0.724570 | Validation Acc: 0.5469 | Validation F1-Macro: 0.5369\n",
            ".........................................................................................\n",
            "Epoch 27 | Train Loss: 0.755699 | Train Acc: 0.5586 | Train F1-Macro: 0.5584\n",
            "Epoch 27 | Validation Loss: 0.724271 | Validation Acc: 0.5719 | Validation F1-Macro: 0.5578\n",
            ".........................................................................................\n",
            "Epoch 28 | Train Loss: 0.753384 | Train Acc: 0.5639 | Train F1-Macro: 0.5639\n",
            "Epoch 28 | Validation Loss: 0.724048 | Validation Acc: 0.5625 | Validation F1-Macro: 0.5466\n",
            ".........................................................................................\n",
            "Epoch 29 | Train Loss: 0.752638 | Train Acc: 0.5546 | Train F1-Macro: 0.5545\n",
            "Epoch 29 | Validation Loss: 0.721901 | Validation Acc: 0.5656 | Validation F1-Macro: 0.5524\n",
            ".........................................................................................\n",
            "Epoch 30 | Train Loss: 0.747678 | Train Acc: 0.5579 | Train F1-Macro: 0.5574\n",
            "Epoch 30 | Validation Loss: 0.715760 | Validation Acc: 0.5250 | Validation F1-Macro: 0.5241\n",
            ".........................................................................................\n",
            "Epoch 31 | Train Loss: 0.739634 | Train Acc: 0.5682 | Train F1-Macro: 0.5682\n",
            "Epoch 31 | Validation Loss: 0.721253 | Validation Acc: 0.5656 | Validation F1-Macro: 0.5524\n",
            ".........................................................................................\n",
            "Epoch 32 | Train Loss: 0.739802 | Train Acc: 0.5739 | Train F1-Macro: 0.5739\n",
            "Epoch 32 | Validation Loss: 0.721207 | Validation Acc: 0.5625 | Validation F1-Macro: 0.5487\n",
            ".........................................................................................\n",
            "Epoch 33 | Train Loss: 0.742099 | Train Acc: 0.5629 | Train F1-Macro: 0.5626\n",
            "Epoch 33 | Validation Loss: 0.716244 | Validation Acc: 0.5344 | Validation F1-Macro: 0.5320\n",
            ".........................................................................................\n",
            "Epoch 34 | Train Loss: 0.737571 | Train Acc: 0.5707 | Train F1-Macro: 0.5707\n",
            "Epoch 34 | Validation Loss: 0.718270 | Validation Acc: 0.5563 | Validation F1-Macro: 0.5451\n",
            ".........................................................................................\n",
            "Epoch 35 | Train Loss: 0.750645 | Train Acc: 0.5564 | Train F1-Macro: 0.5563\n",
            "Epoch 35 | Validation Loss: 0.720861 | Validation Acc: 0.5531 | Validation F1-Macro: 0.5415\n",
            ".........................................................................................\n",
            "Epoch 36 | Train Loss: 0.740950 | Train Acc: 0.5743 | Train F1-Macro: 0.5739\n",
            "Epoch 36 | Validation Loss: 0.713769 | Validation Acc: 0.5250 | Validation F1-Macro: 0.5218\n",
            ".........................................................................................\n",
            "Epoch 37 | Train Loss: 0.732286 | Train Acc: 0.5650 | Train F1-Macro: 0.5650\n",
            "Epoch 37 | Validation Loss: 0.717997 | Validation Acc: 0.5531 | Validation F1-Macro: 0.5415\n",
            ".........................................................................................\n",
            "Epoch 38 | Train Loss: 0.746007 | Train Acc: 0.5668 | Train F1-Macro: 0.5667\n",
            "Epoch 38 | Validation Loss: 0.716612 | Validation Acc: 0.5625 | Validation F1-Macro: 0.5524\n",
            ".........................................................................................\n",
            "Epoch 39 | Train Loss: 0.749808 | Train Acc: 0.5611 | Train F1-Macro: 0.5611\n",
            "Epoch 39 | Validation Loss: 0.720146 | Validation Acc: 0.5563 | Validation F1-Macro: 0.5401\n",
            ".........................................................................................\n",
            "Epoch 40 | Train Loss: 0.735163 | Train Acc: 0.5804 | Train F1-Macro: 0.5802\n",
            "Epoch 40 | Validation Loss: 0.712086 | Validation Acc: 0.5312 | Validation F1-Macro: 0.5276\n",
            ".........................................................................................\n",
            "Epoch 41 | Train Loss: 0.717638 | Train Acc: 0.5843 | Train F1-Macro: 0.5841\n",
            "Epoch 41 | Validation Loss: 0.710179 | Validation Acc: 0.5344 | Validation F1-Macro: 0.5310\n",
            ".........................................................................................\n",
            "Epoch 42 | Train Loss: 0.733731 | Train Acc: 0.5779 | Train F1-Macro: 0.5778\n",
            "Epoch 42 | Validation Loss: 0.713665 | Validation Acc: 0.5500 | Validation F1-Macro: 0.5413\n",
            ".........................................................................................\n",
            "Epoch 43 | Train Loss: 0.733577 | Train Acc: 0.5757 | Train F1-Macro: 0.5756\n",
            "Epoch 43 | Validation Loss: 0.712085 | Validation Acc: 0.5563 | Validation F1-Macro: 0.5499\n",
            ".........................................................................................\n",
            "Epoch 44 | Train Loss: 0.727909 | Train Acc: 0.5700 | Train F1-Macro: 0.5699\n",
            "Epoch 44 | Validation Loss: 0.714749 | Validation Acc: 0.5500 | Validation F1-Macro: 0.5387\n",
            ".........................................................................................\n",
            "Epoch 45 | Train Loss: 0.726254 | Train Acc: 0.5686 | Train F1-Macro: 0.5685\n",
            "Epoch 45 | Validation Loss: 0.712794 | Validation Acc: 0.5625 | Validation F1-Macro: 0.5556\n",
            ".........................................................................................\n",
            "Epoch 46 | Train Loss: 0.727173 | Train Acc: 0.5686 | Train F1-Macro: 0.5685\n",
            "Epoch 46 | Validation Loss: 0.712371 | Validation Acc: 0.5500 | Validation F1-Macro: 0.5405\n",
            ".........................................................................................\n",
            "Epoch 47 | Train Loss: 0.731188 | Train Acc: 0.5732 | Train F1-Macro: 0.5732\n",
            "Epoch 47 | Validation Loss: 0.720100 | Validation Acc: 0.5656 | Validation F1-Macro: 0.5481\n",
            ".........................................................................................\n",
            "Epoch 48 | Train Loss: 0.723415 | Train Acc: 0.5779 | Train F1-Macro: 0.5776\n",
            "Epoch 48 | Validation Loss: 0.713420 | Validation Acc: 0.5500 | Validation F1-Macro: 0.5387\n",
            ".........................................................................................\n",
            "Epoch 49 | Train Loss: 0.719531 | Train Acc: 0.5857 | Train F1-Macro: 0.5856\n",
            "Epoch 49 | Validation Loss: 0.715017 | Validation Acc: 0.5656 | Validation F1-Macro: 0.5514\n",
            ".........................................................................................\n",
            "Epoch 50 | Train Loss: 0.710974 | Train Acc: 0.5857 | Train F1-Macro: 0.5857\n",
            "Epoch 50 | Validation Loss: 0.713534 | Validation Acc: 0.5656 | Validation F1-Macro: 0.5524\n",
            ".........................................................................................\n",
            "Test Accuracy: 0.5376\n",
            "Test F1-Macro: 0.5375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_obj = Train(embed_dim=50, pretrained_embeddings=True, epoch=50, lr=0.0001, dropout=0.2, weight_decay=0.00001, filter_sizes=[3, 4, 5], num_filters=[150, 150, 150])\n",
        "model = train_obj.train_model(device, train_dataloader, val_dataloader)\n",
        "test_model(model, device, test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQQvUb9ouXy-",
        "outputId": "7ea19c14-a4dc-463c-98a0-7b325c16f7e1"
      },
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using pretrained embedding\n",
            "Start training...\n",
            "\n",
            "Epoch  1 | Train Loss: 0.892396 | Train Acc: 0.4904 | Train F1-Macro: 0.4841\n",
            "Epoch  1 | Validation Loss: 0.702505 | Validation Acc: 0.5281 | Validation F1-Macro: 0.5273\n",
            ".........................................................................................\n",
            "Epoch  2 | Train Loss: 0.873316 | Train Acc: 0.4846 | Train F1-Macro: 0.4845\n",
            "Epoch  2 | Validation Loss: 0.707846 | Validation Acc: 0.5188 | Validation F1-Macro: 0.5187\n",
            ".........................................................................................\n",
            "Epoch  3 | Train Loss: 0.882157 | Train Acc: 0.4875 | Train F1-Macro: 0.4875\n",
            "Epoch  3 | Validation Loss: 0.705366 | Validation Acc: 0.5281 | Validation F1-Macro: 0.5281\n",
            ".........................................................................................\n",
            "Epoch  4 | Train Loss: 0.882540 | Train Acc: 0.4807 | Train F1-Macro: 0.4807\n",
            "Epoch  4 | Validation Loss: 0.704791 | Validation Acc: 0.5312 | Validation F1-Macro: 0.5312\n",
            ".........................................................................................\n",
            "Epoch  5 | Train Loss: 0.840101 | Train Acc: 0.5021 | Train F1-Macro: 0.5020\n",
            "Epoch  5 | Validation Loss: 0.703367 | Validation Acc: 0.5312 | Validation F1-Macro: 0.5312\n",
            ".........................................................................................\n",
            "Epoch  6 | Train Loss: 0.845409 | Train Acc: 0.5004 | Train F1-Macro: 0.5003\n",
            "Epoch  6 | Validation Loss: 0.701824 | Validation Acc: 0.5312 | Validation F1-Macro: 0.5312\n",
            ".........................................................................................\n",
            "Epoch  7 | Train Loss: 0.870039 | Train Acc: 0.4864 | Train F1-Macro: 0.4864\n",
            "Epoch  7 | Validation Loss: 0.701113 | Validation Acc: 0.5375 | Validation F1-Macro: 0.5375\n",
            ".........................................................................................\n",
            "Epoch  8 | Train Loss: 0.831406 | Train Acc: 0.5139 | Train F1-Macro: 0.5137\n",
            "Epoch  8 | Validation Loss: 0.700705 | Validation Acc: 0.5188 | Validation F1-Macro: 0.5187\n",
            ".........................................................................................\n",
            "Epoch  9 | Train Loss: 0.840927 | Train Acc: 0.5111 | Train F1-Macro: 0.5110\n",
            "Epoch  9 | Validation Loss: 0.699602 | Validation Acc: 0.5344 | Validation F1-Macro: 0.5344\n",
            ".........................................................................................\n",
            "Epoch 10 | Train Loss: 0.835286 | Train Acc: 0.5025 | Train F1-Macro: 0.5024\n",
            "Epoch 10 | Validation Loss: 0.699108 | Validation Acc: 0.5094 | Validation F1-Macro: 0.5091\n",
            ".........................................................................................\n",
            "Epoch 11 | Train Loss: 0.842826 | Train Acc: 0.5007 | Train F1-Macro: 0.5007\n",
            "Epoch 11 | Validation Loss: 0.698467 | Validation Acc: 0.5094 | Validation F1-Macro: 0.5091\n",
            ".........................................................................................\n",
            "Epoch 12 | Train Loss: 0.830608 | Train Acc: 0.5161 | Train F1-Macro: 0.5160\n",
            "Epoch 12 | Validation Loss: 0.697869 | Validation Acc: 0.5094 | Validation F1-Macro: 0.5091\n",
            ".........................................................................................\n",
            "Epoch 13 | Train Loss: 0.832789 | Train Acc: 0.5182 | Train F1-Macro: 0.5182\n",
            "Epoch 13 | Validation Loss: 0.696923 | Validation Acc: 0.5062 | Validation F1-Macro: 0.5059\n",
            ".........................................................................................\n",
            "Epoch 14 | Train Loss: 0.815164 | Train Acc: 0.5182 | Train F1-Macro: 0.5182\n",
            "Epoch 14 | Validation Loss: 0.695966 | Validation Acc: 0.5094 | Validation F1-Macro: 0.5088\n",
            ".........................................................................................\n",
            "Epoch 15 | Train Loss: 0.833427 | Train Acc: 0.5132 | Train F1-Macro: 0.5132\n",
            "Epoch 15 | Validation Loss: 0.696569 | Validation Acc: 0.5156 | Validation F1-Macro: 0.5146\n",
            ".........................................................................................\n",
            "Epoch 16 | Train Loss: 0.804641 | Train Acc: 0.5271 | Train F1-Macro: 0.5271\n",
            "Epoch 16 | Validation Loss: 0.693259 | Validation Acc: 0.5188 | Validation F1-Macro: 0.5187\n",
            ".........................................................................................\n",
            "Epoch 17 | Train Loss: 0.815651 | Train Acc: 0.5164 | Train F1-Macro: 0.5164\n",
            "Epoch 17 | Validation Loss: 0.692805 | Validation Acc: 0.5188 | Validation F1-Macro: 0.5187\n",
            ".........................................................................................\n",
            "Epoch 18 | Train Loss: 0.818739 | Train Acc: 0.5229 | Train F1-Macro: 0.5229\n",
            "Epoch 18 | Validation Loss: 0.693468 | Validation Acc: 0.5125 | Validation F1-Macro: 0.5118\n",
            ".........................................................................................\n",
            "Epoch 19 | Train Loss: 0.816404 | Train Acc: 0.5250 | Train F1-Macro: 0.5250\n",
            "Epoch 19 | Validation Loss: 0.692759 | Validation Acc: 0.5156 | Validation F1-Macro: 0.5151\n",
            ".........................................................................................\n",
            "Epoch 20 | Train Loss: 0.801344 | Train Acc: 0.5250 | Train F1-Macro: 0.5250\n",
            "Epoch 20 | Validation Loss: 0.692376 | Validation Acc: 0.5219 | Validation F1-Macro: 0.5202\n",
            ".........................................................................................\n",
            "Epoch 21 | Train Loss: 0.789206 | Train Acc: 0.5382 | Train F1-Macro: 0.5382\n",
            "Epoch 21 | Validation Loss: 0.692031 | Validation Acc: 0.5219 | Validation F1-Macro: 0.5202\n",
            ".........................................................................................\n",
            "Epoch 22 | Train Loss: 0.805661 | Train Acc: 0.5136 | Train F1-Macro: 0.5135\n",
            "Epoch 22 | Validation Loss: 0.691963 | Validation Acc: 0.5219 | Validation F1-Macro: 0.5202\n",
            ".........................................................................................\n",
            "Epoch 23 | Train Loss: 0.800703 | Train Acc: 0.5214 | Train F1-Macro: 0.5214\n",
            "Epoch 23 | Validation Loss: 0.692439 | Validation Acc: 0.5281 | Validation F1-Macro: 0.5257\n",
            ".........................................................................................\n",
            "Epoch 24 | Train Loss: 0.787282 | Train Acc: 0.5329 | Train F1-Macro: 0.5328\n",
            "Epoch 24 | Validation Loss: 0.697136 | Validation Acc: 0.5406 | Validation F1-Macro: 0.5337\n",
            ".........................................................................................\n",
            "Epoch 25 | Train Loss: 0.798026 | Train Acc: 0.5250 | Train F1-Macro: 0.5250\n",
            "Epoch 25 | Validation Loss: 0.691315 | Validation Acc: 0.5312 | Validation F1-Macro: 0.5281\n",
            ".........................................................................................\n",
            "Epoch 26 | Train Loss: 0.793385 | Train Acc: 0.5207 | Train F1-Macro: 0.5207\n",
            "Epoch 26 | Validation Loss: 0.692902 | Validation Acc: 0.5375 | Validation F1-Macro: 0.5322\n",
            ".........................................................................................\n",
            "Epoch 27 | Train Loss: 0.781522 | Train Acc: 0.5364 | Train F1-Macro: 0.5364\n",
            "Epoch 27 | Validation Loss: 0.688674 | Validation Acc: 0.5219 | Validation F1-Macro: 0.5213\n",
            ".........................................................................................\n",
            "Epoch 28 | Train Loss: 0.784846 | Train Acc: 0.5411 | Train F1-Macro: 0.5411\n",
            "Epoch 28 | Validation Loss: 0.688143 | Validation Acc: 0.5281 | Validation F1-Macro: 0.5278\n",
            ".........................................................................................\n",
            "Epoch 29 | Train Loss: 0.778306 | Train Acc: 0.5421 | Train F1-Macro: 0.5421\n",
            "Epoch 29 | Validation Loss: 0.695365 | Validation Acc: 0.5312 | Validation F1-Macro: 0.5230\n",
            ".........................................................................................\n",
            "Epoch 30 | Train Loss: 0.774568 | Train Acc: 0.5468 | Train F1-Macro: 0.5467\n",
            "Epoch 30 | Validation Loss: 0.691407 | Validation Acc: 0.5312 | Validation F1-Macro: 0.5252\n",
            ".........................................................................................\n",
            "Epoch 31 | Train Loss: 0.772221 | Train Acc: 0.5329 | Train F1-Macro: 0.5329\n",
            "Epoch 31 | Validation Loss: 0.687990 | Validation Acc: 0.5375 | Validation F1-Macro: 0.5360\n",
            ".........................................................................................\n",
            "Epoch 32 | Train Loss: 0.769339 | Train Acc: 0.5564 | Train F1-Macro: 0.5564\n",
            "Epoch 32 | Validation Loss: 0.690369 | Validation Acc: 0.5312 | Validation F1-Macro: 0.5252\n",
            ".........................................................................................\n",
            "Epoch 33 | Train Loss: 0.761398 | Train Acc: 0.5514 | Train F1-Macro: 0.5514\n",
            "Epoch 33 | Validation Loss: 0.689339 | Validation Acc: 0.5281 | Validation F1-Macro: 0.5231\n",
            ".........................................................................................\n",
            "Epoch 34 | Train Loss: 0.776050 | Train Acc: 0.5386 | Train F1-Macro: 0.5386\n",
            "Epoch 34 | Validation Loss: 0.686911 | Validation Acc: 0.5406 | Validation F1-Macro: 0.5393\n",
            ".........................................................................................\n",
            "Epoch 35 | Train Loss: 0.761201 | Train Acc: 0.5504 | Train F1-Macro: 0.5503\n",
            "Epoch 35 | Validation Loss: 0.690285 | Validation Acc: 0.5344 | Validation F1-Macro: 0.5281\n",
            ".........................................................................................\n",
            "Epoch 36 | Train Loss: 0.764634 | Train Acc: 0.5464 | Train F1-Macro: 0.5464\n",
            "Epoch 36 | Validation Loss: 0.687415 | Validation Acc: 0.5219 | Validation F1-Macro: 0.5189\n",
            ".........................................................................................\n",
            "Epoch 37 | Train Loss: 0.762997 | Train Acc: 0.5454 | Train F1-Macro: 0.5453\n",
            "Epoch 37 | Validation Loss: 0.691287 | Validation Acc: 0.5344 | Validation F1-Macro: 0.5274\n",
            ".........................................................................................\n",
            "Epoch 38 | Train Loss: 0.745507 | Train Acc: 0.5582 | Train F1-Macro: 0.5582\n",
            "Epoch 38 | Validation Loss: 0.688870 | Validation Acc: 0.5312 | Validation F1-Macro: 0.5259\n",
            ".........................................................................................\n",
            "Epoch 39 | Train Loss: 0.752844 | Train Acc: 0.5589 | Train F1-Macro: 0.5589\n",
            "Epoch 39 | Validation Loss: 0.687098 | Validation Acc: 0.5281 | Validation F1-Macro: 0.5257\n",
            ".........................................................................................\n",
            "Epoch 40 | Train Loss: 0.760616 | Train Acc: 0.5554 | Train F1-Macro: 0.5554\n",
            "Epoch 40 | Validation Loss: 0.690367 | Validation Acc: 0.5375 | Validation F1-Macro: 0.5302\n",
            ".........................................................................................\n",
            "Epoch 41 | Train Loss: 0.753222 | Train Acc: 0.5529 | Train F1-Macro: 0.5528\n",
            "Epoch 41 | Validation Loss: 0.688014 | Validation Acc: 0.5250 | Validation F1-Macro: 0.5208\n",
            ".........................................................................................\n",
            "Epoch 42 | Train Loss: 0.744477 | Train Acc: 0.5554 | Train F1-Macro: 0.5553\n",
            "Epoch 42 | Validation Loss: 0.690802 | Validation Acc: 0.5312 | Validation F1-Macro: 0.5222\n",
            ".........................................................................................\n",
            "Epoch 43 | Train Loss: 0.742603 | Train Acc: 0.5611 | Train F1-Macro: 0.5611\n",
            "Epoch 43 | Validation Loss: 0.695255 | Validation Acc: 0.5656 | Validation F1-Macro: 0.5514\n",
            ".........................................................................................\n",
            "Epoch 44 | Train Loss: 0.739033 | Train Acc: 0.5593 | Train F1-Macro: 0.5591\n",
            "Epoch 44 | Validation Loss: 0.686189 | Validation Acc: 0.5250 | Validation F1-Macro: 0.5218\n",
            ".........................................................................................\n",
            "Epoch 45 | Train Loss: 0.742016 | Train Acc: 0.5604 | Train F1-Macro: 0.5603\n",
            "Epoch 45 | Validation Loss: 0.683185 | Validation Acc: 0.5406 | Validation F1-Macro: 0.5399\n",
            ".........................................................................................\n",
            "Epoch 46 | Train Loss: 0.739273 | Train Acc: 0.5654 | Train F1-Macro: 0.5651\n",
            "Epoch 46 | Validation Loss: 0.690869 | Validation Acc: 0.5469 | Validation F1-Macro: 0.5360\n",
            ".........................................................................................\n",
            "Epoch 47 | Train Loss: 0.734994 | Train Acc: 0.5579 | Train F1-Macro: 0.5578\n",
            "Epoch 47 | Validation Loss: 0.689239 | Validation Acc: 0.5531 | Validation F1-Macro: 0.5449\n",
            ".........................................................................................\n",
            "Epoch 48 | Train Loss: 0.732013 | Train Acc: 0.5600 | Train F1-Macro: 0.5600\n",
            "Epoch 48 | Validation Loss: 0.686057 | Validation Acc: 0.5250 | Validation F1-Macro: 0.5218\n",
            ".........................................................................................\n",
            "Epoch 49 | Train Loss: 0.738420 | Train Acc: 0.5593 | Train F1-Macro: 0.5593\n",
            "Epoch 49 | Validation Loss: 0.688133 | Validation Acc: 0.5437 | Validation F1-Macro: 0.5365\n",
            ".........................................................................................\n",
            "Epoch 50 | Train Loss: 0.730133 | Train Acc: 0.5729 | Train F1-Macro: 0.5728\n",
            "Epoch 50 | Validation Loss: 0.686538 | Validation Acc: 0.5469 | Validation F1-Macro: 0.5414\n",
            ".........................................................................................\n",
            "Test Accuracy: 0.5493\n",
            "Test F1-Macro: 0.5485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Best Parameter Combination\n",
        "\n",
        "embed_dim=300,\n",
        "\n",
        "pretrained_embeddings=True,\n",
        "\n",
        "epoch=50,\n",
        "\n",
        "lr=0.0001,\n",
        "\n",
        "dropout=0.5,\n",
        "\n",
        "weight_decay=0.001,$\n",
        "\n",
        "filter_sizes=[3, 3, 4, 4, 5],\n",
        "\n",
        "num_filters=[100, 100, 100, 100, 100]"
      ],
      "metadata": {
        "id": "FKFlc1a7ybT8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 2: Emotional Recognition Model: Anger or Sadness\n",
        "\n",
        "In this section, we will choose data from anger (0) and sadness (3) classes and train a Emotion Recognition model using the best hyperparamters we received in previous section."
      ],
      "metadata": {
        "id": "7XSTH6M8ztXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "# select Anger and Sadness data\n",
        "train_d_as = [data for data, label in zip(train_data, train_labels) if label in ('0', '3')]\n",
        "train_l_as = [label for label in train_labels if label in ('0', '3')]\n",
        "train_l_as = [\"1\" if value == \"3\" else value for value in train_l_as]\n",
        "\n",
        "val_d_as = [data for data, label in zip(val_data, val_labels) if label in ('0', '3')]\n",
        "val_l_as = [label for label in val_labels if label in ('0', '3')]\n",
        "val_l_as = [\"1\" if value == \"3\" else value for value in val_l_as]\n",
        "\n",
        "test_d_as = [data for data, label in zip(test_data, test_labels) if label in ('0', '3')]\n",
        "test_l_as = [label for label in test_labels if label in ('0', '3')]\n",
        "test_l_as = [\"1\" if value == \"3\" else value for value in test_l_as]\n",
        "\n",
        "# balance data\n",
        "train_d_as, train_l_as =  balance_dataset(train_d_as, train_l_as)\n",
        "val_d_as, val_l_as =  balance_dataset(val_d_as, val_l_as)\n",
        "test_d_as, test_l_as =  balance_dataset(test_d_as, test_l_as)\n",
        "\n",
        "# tokenizing, encoding, converting to tensors\n",
        "train_id_as, word2idx = get_tokenized_encoded_ids(train_d_as)\n",
        "val_id_as, _ = get_tokenized_encoded_ids(val_d_as)\n",
        "test_id_as, _ = get_tokenized_encoded_ids(test_d_as)\n",
        "\n",
        "# converting labels to tensors\n",
        "train_l_as = get_tensor_labels(train_l_as)\n",
        "val_l_as = get_tensor_labels(val_l_as)\n",
        "test_l_as = get_tensor_labels(test_l_as)\n",
        "\n",
        "# prepare dataloader\n",
        "random_seed = 42\n",
        "train_dataset = TensorDataset(train_id_as, train_l_as)\n",
        "train_sampler = RandomSampler(train_dataset, generator=torch.Generator().manual_seed(random_seed))\n",
        "val_dataset = TensorDataset(val_id_as, val_l_as)\n",
        "test_dataset = TensorDataset(test_id_as, test_l_as)\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "gOuMEJUhvCRo"
      },
      "execution_count": 318,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train and test the data with best hyperparameter\n",
        "train_obj = Train(embed_dim=300, pretrained_embeddings=True, epoch=50, lr=0.0001, dropout=0.5, weight_decay=0.001, filter_sizes=[3, 3, 4, 4, 5], num_filters=[100, 100, 100, 100, 100])\n",
        "model = train_obj.train_model(device, train_dataloader, val_dataloader)\n",
        "test_model(model, device, test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgwUeiWEFPib",
        "outputId": "86ec7291-24c8-48e0-88d4-d2eb2e459fa9"
      },
      "execution_count": 319,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using pretrained embedding\n",
            "Start training...\n",
            "\n",
            "Epoch  1 | Train Loss: 1.130486 | Train Acc: 0.5025 | Train F1-Macro: 0.5003\n",
            "Epoch  1 | Validation Loss: 0.727938 | Validation Acc: 0.5000 | Validation F1-Macro: 0.4921\n",
            ".........................................................................................\n",
            "Epoch  2 | Train Loss: 1.092994 | Train Acc: 0.4957 | Train F1-Macro: 0.4957\n",
            "Epoch  2 | Validation Loss: 0.744883 | Validation Acc: 0.5188 | Validation F1-Macro: 0.5181\n",
            ".........................................................................................\n",
            "Epoch  3 | Train Loss: 1.066418 | Train Acc: 0.4982 | Train F1-Macro: 0.4982\n",
            "Epoch  3 | Validation Loss: 0.741573 | Validation Acc: 0.5188 | Validation F1-Macro: 0.5181\n",
            ".........................................................................................\n",
            "Epoch  4 | Train Loss: 1.094183 | Train Acc: 0.4936 | Train F1-Macro: 0.4935\n",
            "Epoch  4 | Validation Loss: 0.739477 | Validation Acc: 0.5188 | Validation F1-Macro: 0.5181\n",
            ".........................................................................................\n",
            "Epoch  5 | Train Loss: 1.019758 | Train Acc: 0.5132 | Train F1-Macro: 0.5132\n",
            "Epoch  5 | Validation Loss: 0.737113 | Validation Acc: 0.5250 | Validation F1-Macro: 0.5241\n",
            ".........................................................................................\n",
            "Epoch  6 | Train Loss: 1.038959 | Train Acc: 0.5211 | Train F1-Macro: 0.5211\n",
            "Epoch  6 | Validation Loss: 0.739214 | Validation Acc: 0.5062 | Validation F1-Macro: 0.5019\n",
            ".........................................................................................\n",
            "Epoch  7 | Train Loss: 1.020466 | Train Acc: 0.5021 | Train F1-Macro: 0.5016\n",
            "Epoch  7 | Validation Loss: 0.734062 | Validation Acc: 0.5062 | Validation F1-Macro: 0.5061\n",
            ".........................................................................................\n",
            "Epoch  8 | Train Loss: 0.998198 | Train Acc: 0.5168 | Train F1-Macro: 0.5168\n",
            "Epoch  8 | Validation Loss: 0.730985 | Validation Acc: 0.5312 | Validation F1-Macro: 0.5312\n",
            ".........................................................................................\n",
            "Epoch  9 | Train Loss: 1.007067 | Train Acc: 0.5211 | Train F1-Macro: 0.5210\n",
            "Epoch  9 | Validation Loss: 0.728441 | Validation Acc: 0.5375 | Validation F1-Macro: 0.5374\n",
            ".........................................................................................\n",
            "Epoch 10 | Train Loss: 0.980216 | Train Acc: 0.5161 | Train F1-Macro: 0.5160\n",
            "Epoch 10 | Validation Loss: 0.728167 | Validation Acc: 0.5094 | Validation F1-Macro: 0.5090\n",
            ".........................................................................................\n",
            "Epoch 11 | Train Loss: 0.975595 | Train Acc: 0.5171 | Train F1-Macro: 0.5171\n",
            "Epoch 11 | Validation Loss: 0.726394 | Validation Acc: 0.5219 | Validation F1-Macro: 0.5218\n",
            ".........................................................................................\n",
            "Epoch 12 | Train Loss: 0.964731 | Train Acc: 0.5239 | Train F1-Macro: 0.5239\n",
            "Epoch 12 | Validation Loss: 0.724145 | Validation Acc: 0.5250 | Validation F1-Macro: 0.5247\n",
            ".........................................................................................\n",
            "Epoch 13 | Train Loss: 0.944189 | Train Acc: 0.5236 | Train F1-Macro: 0.5236\n",
            "Epoch 13 | Validation Loss: 0.722671 | Validation Acc: 0.5281 | Validation F1-Macro: 0.5279\n",
            ".........................................................................................\n",
            "Epoch 14 | Train Loss: 0.946816 | Train Acc: 0.5214 | Train F1-Macro: 0.5213\n",
            "Epoch 14 | Validation Loss: 0.721125 | Validation Acc: 0.5219 | Validation F1-Macro: 0.5215\n",
            ".........................................................................................\n",
            "Epoch 15 | Train Loss: 0.917182 | Train Acc: 0.5518 | Train F1-Macro: 0.5518\n",
            "Epoch 15 | Validation Loss: 0.720922 | Validation Acc: 0.5344 | Validation F1-Macro: 0.5343\n",
            ".........................................................................................\n",
            "Epoch 16 | Train Loss: 0.934490 | Train Acc: 0.5329 | Train F1-Macro: 0.5329\n",
            "Epoch 16 | Validation Loss: 0.719275 | Validation Acc: 0.5125 | Validation F1-Macro: 0.5118\n",
            ".........................................................................................\n",
            "Epoch 17 | Train Loss: 0.882991 | Train Acc: 0.5486 | Train F1-Macro: 0.5485\n",
            "Epoch 17 | Validation Loss: 0.717829 | Validation Acc: 0.5188 | Validation F1-Macro: 0.5175\n",
            ".........................................................................................\n",
            "Epoch 18 | Train Loss: 0.898227 | Train Acc: 0.5371 | Train F1-Macro: 0.5371\n",
            "Epoch 18 | Validation Loss: 0.717476 | Validation Acc: 0.5156 | Validation F1-Macro: 0.5143\n",
            ".........................................................................................\n",
            "Epoch 19 | Train Loss: 0.889117 | Train Acc: 0.5471 | Train F1-Macro: 0.5471\n",
            "Epoch 19 | Validation Loss: 0.717018 | Validation Acc: 0.5312 | Validation F1-Macro: 0.5271\n",
            ".........................................................................................\n",
            "Epoch 20 | Train Loss: 0.859407 | Train Acc: 0.5489 | Train F1-Macro: 0.5489\n",
            "Epoch 20 | Validation Loss: 0.715450 | Validation Acc: 0.5406 | Validation F1-Macro: 0.5390\n",
            ".........................................................................................\n",
            "Epoch 21 | Train Loss: 0.895002 | Train Acc: 0.5354 | Train F1-Macro: 0.5354\n",
            "Epoch 21 | Validation Loss: 0.718237 | Validation Acc: 0.5469 | Validation F1-Macro: 0.5369\n",
            ".........................................................................................\n",
            "Epoch 22 | Train Loss: 0.884440 | Train Acc: 0.5496 | Train F1-Macro: 0.5496\n",
            "Epoch 22 | Validation Loss: 0.713587 | Validation Acc: 0.5406 | Validation F1-Macro: 0.5373\n",
            ".........................................................................................\n",
            "Epoch 23 | Train Loss: 0.875993 | Train Acc: 0.5529 | Train F1-Macro: 0.5529\n",
            "Epoch 23 | Validation Loss: 0.713727 | Validation Acc: 0.5531 | Validation F1-Macro: 0.5483\n",
            ".........................................................................................\n",
            "Epoch 24 | Train Loss: 0.859409 | Train Acc: 0.5618 | Train F1-Macro: 0.5618\n",
            "Epoch 24 | Validation Loss: 0.712895 | Validation Acc: 0.5500 | Validation F1-Macro: 0.5449\n",
            ".........................................................................................\n",
            "Epoch 25 | Train Loss: 0.838553 | Train Acc: 0.5550 | Train F1-Macro: 0.5550\n",
            "Epoch 25 | Validation Loss: 0.709650 | Validation Acc: 0.5594 | Validation F1-Macro: 0.5562\n",
            ".........................................................................................\n",
            "Epoch 26 | Train Loss: 0.826744 | Train Acc: 0.5704 | Train F1-Macro: 0.5703\n",
            "Epoch 26 | Validation Loss: 0.710640 | Validation Acc: 0.5563 | Validation F1-Macro: 0.5518\n",
            ".........................................................................................\n",
            "Epoch 27 | Train Loss: 0.802504 | Train Acc: 0.5771 | Train F1-Macro: 0.5771\n",
            "Epoch 27 | Validation Loss: 0.709419 | Validation Acc: 0.5656 | Validation F1-Macro: 0.5620\n",
            ".........................................................................................\n",
            "Epoch 28 | Train Loss: 0.810573 | Train Acc: 0.5764 | Train F1-Macro: 0.5764\n",
            "Epoch 28 | Validation Loss: 0.709210 | Validation Acc: 0.5594 | Validation F1-Macro: 0.5552\n",
            ".........................................................................................\n",
            "Epoch 29 | Train Loss: 0.848378 | Train Acc: 0.5629 | Train F1-Macro: 0.5628\n",
            "Epoch 29 | Validation Loss: 0.708748 | Validation Acc: 0.5625 | Validation F1-Macro: 0.5586\n",
            ".........................................................................................\n",
            "Epoch 30 | Train Loss: 0.806784 | Train Acc: 0.5632 | Train F1-Macro: 0.5632\n",
            "Epoch 30 | Validation Loss: 0.706220 | Validation Acc: 0.5625 | Validation F1-Macro: 0.5608\n",
            ".........................................................................................\n",
            "Epoch 31 | Train Loss: 0.796317 | Train Acc: 0.5879 | Train F1-Macro: 0.5878\n",
            "Epoch 31 | Validation Loss: 0.707238 | Validation Acc: 0.5563 | Validation F1-Macro: 0.5518\n",
            ".........................................................................................\n",
            "Epoch 32 | Train Loss: 0.814611 | Train Acc: 0.5725 | Train F1-Macro: 0.5725\n",
            "Epoch 32 | Validation Loss: 0.708068 | Validation Acc: 0.5531 | Validation F1-Macro: 0.5471\n",
            ".........................................................................................\n",
            "Epoch 33 | Train Loss: 0.798002 | Train Acc: 0.5761 | Train F1-Macro: 0.5761\n",
            "Epoch 33 | Validation Loss: 0.704929 | Validation Acc: 0.5656 | Validation F1-Macro: 0.5620\n",
            ".........................................................................................\n",
            "Epoch 34 | Train Loss: 0.803873 | Train Acc: 0.5786 | Train F1-Macro: 0.5786\n",
            "Epoch 34 | Validation Loss: 0.705236 | Validation Acc: 0.5594 | Validation F1-Macro: 0.5552\n",
            ".........................................................................................\n",
            "Epoch 35 | Train Loss: 0.784161 | Train Acc: 0.5904 | Train F1-Macro: 0.5903\n",
            "Epoch 35 | Validation Loss: 0.710532 | Validation Acc: 0.5437 | Validation F1-Macro: 0.5314\n",
            ".........................................................................................\n",
            "Epoch 36 | Train Loss: 0.787983 | Train Acc: 0.5832 | Train F1-Macro: 0.5832\n",
            "Epoch 36 | Validation Loss: 0.705773 | Validation Acc: 0.5500 | Validation F1-Macro: 0.5436\n",
            ".........................................................................................\n",
            "Epoch 37 | Train Loss: 0.780176 | Train Acc: 0.5729 | Train F1-Macro: 0.5728\n",
            "Epoch 37 | Validation Loss: 0.711610 | Validation Acc: 0.5594 | Validation F1-Macro: 0.5416\n",
            ".........................................................................................\n",
            "Epoch 38 | Train Loss: 0.783750 | Train Acc: 0.5889 | Train F1-Macro: 0.5889\n",
            "Epoch 38 | Validation Loss: 0.707708 | Validation Acc: 0.5500 | Validation F1-Macro: 0.5387\n",
            ".........................................................................................\n",
            "Epoch 39 | Train Loss: 0.777918 | Train Acc: 0.5846 | Train F1-Macro: 0.5846\n",
            "Epoch 39 | Validation Loss: 0.713805 | Validation Acc: 0.5500 | Validation F1-Macro: 0.5287\n",
            ".........................................................................................\n",
            "Epoch 40 | Train Loss: 0.779732 | Train Acc: 0.5721 | Train F1-Macro: 0.5721\n",
            "Epoch 40 | Validation Loss: 0.705362 | Validation Acc: 0.5656 | Validation F1-Macro: 0.5569\n",
            ".........................................................................................\n",
            "Epoch 41 | Train Loss: 0.791882 | Train Acc: 0.5679 | Train F1-Macro: 0.5678\n",
            "Epoch 41 | Validation Loss: 0.704002 | Validation Acc: 0.5719 | Validation F1-Macro: 0.5661\n",
            ".........................................................................................\n",
            "Epoch 42 | Train Loss: 0.781045 | Train Acc: 0.5729 | Train F1-Macro: 0.5729\n",
            "Epoch 42 | Validation Loss: 0.702113 | Validation Acc: 0.5656 | Validation F1-Macro: 0.5625\n",
            ".........................................................................................\n",
            "Epoch 43 | Train Loss: 0.744395 | Train Acc: 0.6075 | Train F1-Macro: 0.6075\n",
            "Epoch 43 | Validation Loss: 0.701707 | Validation Acc: 0.5687 | Validation F1-Macro: 0.5659\n",
            ".........................................................................................\n",
            "Epoch 44 | Train Loss: 0.733970 | Train Acc: 0.5975 | Train F1-Macro: 0.5975\n",
            "Epoch 44 | Validation Loss: 0.704377 | Validation Acc: 0.5656 | Validation F1-Macro: 0.5569\n",
            ".........................................................................................\n",
            "Epoch 45 | Train Loss: 0.742280 | Train Acc: 0.5964 | Train F1-Macro: 0.5964\n",
            "Epoch 45 | Validation Loss: 0.699979 | Validation Acc: 0.5781 | Validation F1-Macro: 0.5766\n",
            ".........................................................................................\n",
            "Epoch 46 | Train Loss: 0.707301 | Train Acc: 0.6118 | Train F1-Macro: 0.6118\n",
            "Epoch 46 | Validation Loss: 0.704724 | Validation Acc: 0.5563 | Validation F1-Macro: 0.5460\n",
            ".........................................................................................\n",
            "Epoch 47 | Train Loss: 0.753316 | Train Acc: 0.5968 | Train F1-Macro: 0.5968\n",
            "Epoch 47 | Validation Loss: 0.706141 | Validation Acc: 0.5469 | Validation F1-Macro: 0.5320\n",
            ".........................................................................................\n",
            "Epoch 48 | Train Loss: 0.748874 | Train Acc: 0.5846 | Train F1-Macro: 0.5846\n",
            "Epoch 48 | Validation Loss: 0.701578 | Validation Acc: 0.5687 | Validation F1-Macro: 0.5619\n",
            ".........................................................................................\n",
            "Epoch 49 | Train Loss: 0.723260 | Train Acc: 0.6011 | Train F1-Macro: 0.6011\n",
            "Epoch 49 | Validation Loss: 0.699582 | Validation Acc: 0.5750 | Validation F1-Macro: 0.5712\n",
            ".........................................................................................\n",
            "Epoch 50 | Train Loss: 0.712528 | Train Acc: 0.6025 | Train F1-Macro: 0.6024\n",
            "Epoch 50 | Validation Loss: 0.701667 | Validation Acc: 0.5687 | Validation F1-Macro: 0.5604\n",
            ".........................................................................................\n",
            "Test Accuracy: 0.5833\n",
            "Test F1-Macro: 0.5833\n"
          ]
        }
      ]
    }
  ]
}